---
title: "[翻訳] OpenSearch 2.17 のパフォーマンス改善"
emoji: "🚀"
type: "tech"
topics: ["opensearch", "performance", "vectorsearch", "analytics"]
published: true
published_at: 2024-11-27
publication_name: "opensearch"
---

:::message
本記事は [OpenSearch Project Blog](https://opensearch.org/blog/) に投稿された以下の記事を日本語に翻訳したものです。
:::

https://opensearch.org/blog/opensearch-performance-2-17/

OpenSearch のパフォーマンス向上への取り組みは揺るぎないものであり、本記事ではその大きな進歩を紹介します。最近、テキストクエリ、ベクトルストレージとクエリ、インジェストとインデックス作成、ストレージ効率の 4 つの主要分野に投資を集中してきました。さらに、検索とパフォーマンスのロードマップを公開し、パフォーマンスが引き続き最優先事項であることを再確認しました。本記事では、[OpenSearch 2.17](https://github.com/opensearch-project/opensearch-build/blob/main/release-notes/opensearch-release-notes-2.17.0.md) までの継続的なパフォーマンス改善についてお伝えします。

OpenSearch 2.17 は、OpenSearch 1.3 と比較して **6 倍のパフォーマンス向上** を実現し、テキストクエリ、terms 集計、range クエリ、date histogram、ソートなどの主要な操作を強化しています。さらに、セマンティックベクトル検索の改善により、高度に設定可能な設定が可能になり、ニーズに応じてレスポンス時間、精度、コストのバランスを取ることができます。これらの進歩は、OpenSearch を前進させる貢献とコラボレーションを行う献身的なコミュニティの証です。

最初のセクションでは、テキストクエリ、terms 集計、range クエリ、date histogram、ソートなどの主要なクエリ操作に焦点を当てます。これらの改善は、検索と分析アプリケーションの両方で一般的なユースケースを表す [OpenSearch Big5 ワークロード](https://github.com/opensearch-project/opensearch-benchmark-workloads/tree/main/big5)を使用して評価されました。次のセクションではベクトル検索の改善について報告します。最後に、2025 年のロードマップを紹介します。

## 2.17 までのパフォーマンス改善

OpenSearch は創設以来一貫してパフォーマンスを改善しており、バージョン 2.17 もこの傾向を継続しています。以前のバージョンと比較して、OpenSearch 2.17 は改善されたパフォーマンスを提供し、OpenSearch 1.3 と比較して **6 倍の速度向上** を達成し、さまざまなカテゴリでクエリレイテンシを削減しています。以下のグラフは、OpenSearch 1.3 をベースラインとした 90 パーセンタイルレイテンシでのクエリカテゴリ別の相対的な改善を示しています。

![パフォーマンスチャート](/images/opensearch-performance-2-17-improvements/OS-PerformanceChart-ldc@2x-1024x698.png)

### 主なハイライト

ベンチマークに基づいて、以下の主なハイライトを特定しました。

* **全体的なクエリパフォーマンス**: OpenSearch 2.17 は OpenSearch 1.3 と比較して **6 倍優れたパフォーマンス** を提供
* **テキストクエリ**: 多くの OpenSearch ユースケースの基本であるテキスト検索クエリは、OpenSearch 1.3 のベースラインと比較して **63% 高速化**
* **Terms 集計**: ログ分析に重要なこのクエリタイプは、OpenSearch 1.3 と比較して **81% の改善** を示し、より高速で効率的なデータ集計が可能に
* **Date histogram**: Date histogram のパフォーマンスは OpenSearch 1.3 と比較して **97% 改善** し、時系列分析の大幅な速度向上を実現
* **Range クエリ**: OpenSearch 1.3 と比較して **87% のパフォーマンス改善** により、range クエリはより少ないリソースでより迅速に実行
* **ソートとフィルタリング**: OpenSearch 2.17 は OpenSearch 1.3 と比較して **59% の改善** でより高速なソートを提供

## クエリ

OpenSearch には以下のクエリ改善が含まれています。

### テキストクエリ

テキストクエリは、特に高速で正確なドキュメント検索を必要とするアプリケーションにおいて、効果的なテキスト検索の基本です。OpenSearch 2.12 では、100% の再現率やカスタマイズされたランキング戦略を優先する分析やアプリケーションの特定のニーズに対応するために **match_only_text** フィールドを導入しました。このフィールドタイプは、関連性ベースのスコアリングの複雑さを排除することで、インデックスサイズを大幅に削減し、クエリ実行を高速化しました。その結果、**テキストクエリは OpenSearch 2.11 と比較して 47% 高速化、OpenSearch 1.3 と比較して 57% 高速化** しました。

OpenSearch 2.17 では、これらのパフォーマンス向上をさらに増幅しました。**match_only_text** フィールドの基盤の上に構築し、OpenSearch 2.17 はテキストクエリを最適化し、**2.14 と比較して 21% 高速化、1.3 と比較して 63% 高速化** を達成しました。

### Terms および multi-terms 集計

Terms 集計は、複数の基準に基づいて大規模なデータセットをスライスするために重要であり、データ分析ユースケースにとって重要なクエリ操作です。以前の進歩に基づいて、OpenSearch 2.17 はグローバル terms 集計の効率を向上させ、ログデータなどの大規模な不変コレクションを前例のない速度で処理するために term 頻度の最適化を使用しています。

パフォーマンスベンチマークでは、**OpenSearch 2.14 と比較して 61% のパフォーマンス改善** と、全体で **OpenSearch 1.3 と比較して 81% のクエリレイテンシ削減** を示しています。また、**multi-terms 集計クエリは最大 20% のレイテンシ削減** を示しています。さらに、複合キーストレージ用の新しいバイト配列割り当てが不要になったため、**短命オブジェクトのメモリフットプリントが 50〜60% 削減** され、メモリ効率が大幅に改善されました。

OpenSearch 2.17 では、**[wildcard フィールドタイプ](https://github.com/opensearch-project/OpenSearch/pull/13461)** のサポートも導入され、ワイルドカード、プレフィックス、正規表現クエリの高効率な実行が可能になりました。

### Date histogram

Date histogram は時間ベースのデータ分析の基本であり、時系列チャートなどの OpenSearch Dashboards の可視化を支えています。OpenSearch 2.17 では、date histogram クエリは **OpenSearch 2.13 と比較して 55% 高速化、OpenSearch 1.3 と比較して 97% 高速化** し、時系列集計のパフォーマンスを大幅に改善しています。

さらに、ユニーク訪問者、イベントタイプ、製品などの個別値をカウントするための重要なツールである **cardinality 集計** も大幅なパフォーマンス向上を受けました。OpenSearch 2.17 では、すでに収集された個別値を含むドキュメントを動的にプルーニングする[最適化](https://github.com/opensearch-project/OpenSearch/pull/13821)を導入し、冗長な処理を大幅に削減しました。**低カーディナリティリクエスト** では顕著なパフォーマンス向上が見られ、**高カーディナリティリクエスト** では最大 **20%** の改善が見られます。

### Range クエリと数値フィールド

特定の数値または日付範囲内のデータをフィルタリングするために一般的に使用される **range クエリ** は、OpenSearch 2.17 で大幅なパフォーマンス改善を受けました。これらのクエリは、range フィルター処理の進歩と最適化により、**OpenSearch 2.14 と比較して 81% 高速化、OpenSearch 1.3 と比較して 87% 高速化** しています。

検索時に、OpenSearch はクエリを *元のクエリ* からより高速で少ないリソースを使用する *近似クエリ* に書き換えることができるかどうかを評価します。この[近似 range 最適化](https://github.com/opensearch-project/OpenSearch/pull/13788)により、ほとんどのクエリが計算オーバーヘッドを削減しながら同等の結果を提供し、精度を維持しながらパフォーマンスを向上させます。

### ソートとフィルタリング

**ソートパフォーマンス** は OpenSearch 2.x シリーズを通じて焦点となっており、OpenSearch 2.17 は OpenSearch 2.14 と比較してわずかな改善を示していますが、**OpenSearch 1.3 と比較して 59% のパフォーマンス改善** を示しています。

フィルタリングも、大規模なフィルターリストを処理するための **[roaring bitmap エンコーディング](https://github.com/opensearch-project/OpenSearch/pull/14774)** の導入により大幅な進歩を遂げました。このアプローチは、フィルターデータを効率的なビットマップ構造に圧縮することで、メモリとネットワークのオーバーヘッドを最小限に抑えます。

## ベクトル検索

**ディスク最適化ベクトル検索**: OpenSearch ベクトルエンジンは 2.17 リリースでもコスト削減を優先し続けています。このリリースでは、低メモリ環境でもベクトルワークロードの可能性を最大限に活用できるディスク最適化ベクトル検索を導入しました。ディスク最適化ベクトル検索は、強力な圧縮技術であるバイナリ量子化を使用する際に、すぐに使える **32 倍の圧縮** を提供するように設計されています。さらに、圧縮率、サンプリング、リスコアリングなどの設定可能なパラメータを通じて、コスト、レスポンス時間、精度を独自のニーズに合わせて微調整する柔軟性があります。内部ベンチマークによると、OpenSearch のディスク最適化ベクトル検索は、p90 レイテンシ約 200 ms と 0.9 以上の再現率を維持しながら、最大 70% のコスト削減を実現できます。

**メモリフットプリント削減によるコスト改善**: ネイティブエンジン (Faiss および NMSLIB) のベクトル検索機能は OpenSearch 2.17 で大幅に強化されました。このバージョンでは、OpenSearch のバイト圧縮技術が Faiss エンジンの [HNSW](https://github.com/opensearch-project/k-NN/pull/1823) および [IVF](https://github.com/opensearch-project/k-NN/pull/2002) アルゴリズムに拡張され、バイト範囲 ([-128, 127]) 内のベクトルのメモリフットプリントを最大 75% 削減します。これにより、[FP16 量子化](https://opensearch.org/blog/optimizing-opensearch-with-fp16-quantization/)を使用した OpenSearch 2.14 と比較してさらに 25% のメモリフットプリント削減が実現し、OpenSearch 1.3 と比較して全体で最大 85% の削減となります。

**ベクトルインデックス構築の改善**: 2024 年、ベクトルエンジンチームは OpenSearch ベクトルエンジンのパフォーマンス改善に大きな[投資](https://github.com/opensearch-project/k-NN/issues/1599)を行いました。これには、[AVX512 SIMD サポート](https://github.com/opensearch-project/k-NN/issues/2056)の追加、ベクトルインデックスを使用したセグメントレプリケーションに関連する[いくつかのバグ](https://github.com/opensearch-project/k-NN/issues/2277)の修正、[より効率的な KNNVectorsFormat への移行](https://github.com/opensearch-project/k-NN/issues/1853)、[マージ中のインクリメンタルグラフ構築によるメモリフットプリントの削減](https://github.com/opensearch-project/k-NN/issues/1938)が含まれます。インクリメンタルグラフ構築により、完全なデータセットが一度にメモリにロードされるため、インデックス作成中のネイティブメモリフットプリントが大幅に削減されました。この改善により、低メモリ環境での HNSW グラフ構築がサポートされ、OpenSearch 1.3 と比較して全体的な構築時間が約 30% 短縮されます。

**完全検索の改善**: OpenSearch 2.15 では、k-NN プラグインのスクリプトスコアリングに [SIMD 最適化](https://opensearch.org/blog/boosting-k-nn-exact-search/)が追加され、x86 の AVX2 や AVX512、ARM の NEON などの SIMD サポートを持つ CPU で大幅なパフォーマンス向上が実現しました。OpenSearch 2.17 でのさらなる改善により、最適化されたメモリマップファイルアクセスを含む Lucene の新しいベクトルフォーマットが導入されました。これらの強化により、サポートされているハードウェアでの完全 k-NN 検索の検索レイテンシが大幅に削減されます。

## 2025 年のロードマップ

以下の改善が 2025 年の OpenSearch ロードマップに含まれています。

### コア検索エンジン

2025 年には、パフォーマンス、スケーラビリティ、効率の向上を目指したいくつかの主要なイニシアチブで OpenSearch のクエリエンジンの限界を押し広げます。

* **[ストリーミングアーキテクチャ](https://github.com/opensearch-project/OpenSearch/issues/16679)**: リクエスト/レスポンスモデルからストリーミング、処理、リアルタイムでのデータ配信に移行し、メモリオーバーヘッドを削減してクエリ速度を向上
* **[ネイティブ join サポート](https://github.com/opensearch-project/OpenSearch/issues/15185)**: インデックス間の効率的な join 操作を導入し、OpenSearch のクエリ DSL、PPL、SQL と完全に統合してネイティブにサポート
* **ネイティブベクトル化処理**: 最新の CPU SIMD 操作とネイティブコードを使用して、データストリームの処理を最適化し、Java のガベージコレクションのボトルネックを排除
* **[よりスマートなクエリプランニング](https://github.com/opensearch-project/OpenSearch/issues/12390)**: 計算の実行場所と方法を最適化し、不要なデータ転送を削減して並列クエリ実行のパフォーマンスを向上
* **[gRPC ベースの Search API](https://github.com/opensearch-project/OpenSearch/issues/15190)**: Protobuf と gRPC でクライアント-サーバー通信を強化し、オーバーヘッドを削減して検索を高速化
* **[Star-tree インデックス](https://github.com/opensearch-project/OpenSearch/issues/12498)**: star-tree インデックスを使用して集計を事前計算し、集計が多いクエリのより高速で予測可能なパフォーマンスを確保

### ベクトル検索

2025 年には、パフォーマンス改善とコスト削減を目指した以下の主要なイニシアチブへの投資を継続します。

* **GPU と SIMD によるインデックス構築の高速化**: GPU サポートを持つライブラリを使用して k-NN パフォーマンスを向上。ベクトル距離計算は計算負荷が高いため、GPU は計算を高速化し、インデックス構築と検索クエリ時間を短縮可能
* **k-NN インデックスの自動チューニング**: OpenSearch のベクトルデータベースは、多様なワークロードに合わせたアルゴリズムのツールキットを提供。2025 年の目標は、アクセスパターンとハードウェアリソースに基づいてハイパーパラメータと設定を自動チューニングすることで、すぐに使えるエクスペリエンスを向上させること
* **コールド-ウォームティアリング**: バージョン 2.18 では、リモートスナップショットでベクトル検索を有効にするサポートを追加。ストレージとコンピューティングコストを削減するために、ベクトルインデックスを異なるストレージシステムに拡張するためのインデックス読み取り/書き込み操作の分離に引き続き注力
* **メモリフットプリントの削減**: ベクトルインデックスのメモリフットプリントを積極的に削減し続ける。目標の 1 つは、HNSW インデックスをネイティブエンジンに部分的にロードする機能をサポートすること
* **derived source を使用したディスクストレージの削減**: 現在、ベクトルデータは doc-values のようなフォーマットと保存された `_source` フィールドの両方に保存されている。保存された `_source` フィールドは、全体的なベクトルストレージ要件の 60% 以上を占める可能性がある。doc-values のようなフォーマットからベクトルフィールドをソースに注入するカスタム保存フィールドフォーマットを作成し、derived source フィールドを作成する予定

### ニューラル検索

ニューラル検索は、機械学習モデルを使用して検索クエリのセマンティックな意味を理解し、従来のキーワードマッチングを超えます。**密ベクトル検索、疎ベクトル検索、セマンティック理解と語彙検索を組み合わせたハイブリッド検索アプローチを包含します**。OpenSearch 2.9 でニューラル検索機能を導入して以来、テキスト埋め込み、クロスエンコーダーリランキング、疎エンコーディング、ハイブリッド検索を含むように機能を拡張してきました。

2025 年のロードマップでは、パフォーマンスの最適化、機能の強化、採用の簡素化を重視しています。主要なイニシアチブには以下が含まれます。

* **ハイブリッドクエリパフォーマンスの改善**: レイテンシを最大 25% 削減
* **ハイブリッドクエリの説明可能性の導入**: 各サブクエリ結果が最終的なハイブリッドクエリ結果にどのように貢献するかについての洞察を提供し、より良いデバッグとパフォーマンス分析を可能に
* **ハイブリッドクエリ結果を組み合わせるための追加アルゴリズムのサポート**: スコアがランクベースであるため、コストのかかるスコア正規化を回避してハイブリッド検索レイテンシを改善する reciprocal rank fusion (RRF) などのアルゴリズムをサポート
* **ニューラル疎プルーニング戦略の強化**: 重みによるプルーニング、最大重みとの比率によるプルーニング、top-k によるプルーニング、alpha-mass によるプルーニングなどの技術を適用し、パフォーマンスを 20% 改善
* **更新と再インデックス中の推論呼び出しの最適化**: ニューラルおよび疎インジェストパイプラインに必要な推論呼び出しの数を削減し、これらの操作のスループットを 20% 向上
* **マルチフィールド推論呼び出しの統合**: 密および疎ベクトルセマンティック検索のために複数のフィールド推論呼び出しを単一の操作に統合し、マルチフィールド密ベクトルベースのセマンティッククエリの推論レイテンシを 15% 削減
* **リソース制約のあるシステムのメモリ使用量の削減**: 新しい量子化プロセッサを導入してメモリ使用量を 20% 削減し、リソースや接続が限られた環境での効率を改善

## まとめ

OpenSearch は、機能の拡張だけでなく、多様なワークロード全体でパフォーマンス、効率、スケーラビリティを大幅に向上させながら進化し続けています。OpenSearch 2.17 は、テキストクエリ、集計、range クエリ、時系列分析全体でクエリ速度、リソース使用率、メモリ効率の改善を提供し、コミュニティのコミットメントを体現しています。

ディスク最適化ベクトル検索や terms および multi-terms 集計の強化などの主要なイノベーションは、ベクトル検索と分析技術の最前線に立ち続けることへの注力を示しています。さらに、OpenSearch 2.17 のハイブリッドおよびベクトル検索の改善と、ストリーミングアーキテクチャ、gRPC API、よりスマートなクエリプランニングのロードマップ計画は、最新のワークロードの要求を満たすための将来を見据えた戦略を強調しています。

これらの成果は、テスト、フィードバック、開発への貢献が非常に貴重であった広範な OpenSearch コミュニティとのコラボレーションによって可能になりました。共に、現在および将来の課題に対応できる堅牢で効率的な検索および分析エンジンを構築しています。

イノベーションの旅を続け、将来の計画を共有する中で、継続的な更新と洞察については [ブログ](https://opensearch.org/blog)と [GitHub リポジトリ](https://github.com/opensearch-project/OpenSearch)をフォローしてください。
