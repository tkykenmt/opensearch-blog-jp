---
title: "[翻訳] Faiss バイトベクトルでメモリ効率を向上させる"
emoji: "💾"
type: "tech"
topics: ["opensearch", "vectorsearch", "faiss", "quantization", "knn"]
published: true
published_at: 2024-11-26
publication_name: "opensearch"
---

:::message
本記事は [OpenSearch Project Blog](https://opensearch.org/blog/) に投稿された以下の記事を日本語に翻訳したものです。
:::

https://opensearch.org/blog/faiss-byte-vector/

生成 AI と大規模言語モデル (LLM) の人気の高まりにより、効率的なベクトル検索と類似性操作への需要が増加しています。これらのモデルは、テキスト、画像、その他のデータの高次元ベクトル表現に依存することが多いです。これらのベクトルに対する類似性検索や最近傍クエリの実行は、特にベクトルデータベースのサイズが大きくなるにつれて計算コストが高くなります。OpenSearch の Faiss バイトベクトルサポートは、これらの課題に対する有望なソリューションを提供します。

ベクトル検索に float ベクトルの代わりにバイトベクトルを使用すると、メモリ効率とパフォーマンスが大幅に向上します。これは、大規模なベクトルデータベースやリソースが限られた環境で特に有益です。Faiss バイトベクトルを使用すると、量子化された埋め込みを保存でき、メモリ消費を大幅に削減してコストを下げることができます。このアプローチは通常、フル精度 (float) ベクトルを使用する場合と比較して、再現率の損失は最小限に抑えられます。

## Faiss バイトベクトルの使用方法

バイトベクトルは、各次元が -128 から 127 の範囲の符号付き 8 ビット整数であるコンパクトなベクトル表現です。バイトベクトルを使用するには、通常 `float` 形式の入力ベクトルを、取り込み前に `byte` 型に変換する必要があります。このプロセスには、本質的なデータ特性を維持しながら float ベクトルを圧縮する量子化技術が必要です。詳細については、[量子化技術](https://opensearch.org/docs/latest/field-types/supported-field-types/knn-vector#quantization-techniques)を参照してください。

`byte` ベクトルを使用するには、k-NN インデックスを作成する際に `data_type` パラメータを `byte` に設定します (`data_type` パラメータのデフォルト値は `float` です)。

```json
PUT test-index
{
  "settings": {
    "index": {
      "knn": true
    }
  },
  "mappings": {
    "properties": {
      "my_vector1": {
        "type": "knn_vector",
        "dimension": 8,
        "data_type": "byte",
        "method": {
          "name": "hnsw",
          "space_type": "l2",
          "engine": "faiss",
          "parameters": {
            "ef_construction": 100,
            "m": 16
          }
        }
      }
    }
  }
}
```

取り込み時には、ベクトルの各次元がサポートされている [-128, 127] の範囲内であることを確認してください。

```json
PUT test-index/_doc/1
{
  "my_vector": [-126, 28, 127, 0, 10, -45, 12, -110]
}
```

```json
PUT test-index/_doc/2
{
  "my_vector": [100, -25, 4, -67, -2, 127, 99, 0]
}
```

クエリ時には、クエリベクトルもバイト範囲内であることを確認してください。

```json
GET test-index/_search
{
  "size": 2,
  "query": {
    "knn": {
      "my_vector1": {
        "vector": [-1, 45, -100, 125, -128, -8, 5, 10],
        "k": 2
      }
    }
  }
}
```

**注意**: `byte` ベクトルを使用する場合、`float` ベクトルを使用する場合と比較して、再現率の精度がいくらか低下することが予想されます。バイトベクトルは、メモリ使用量の削減と引き換えに最小限の再現率損失を許容する大規模アプリケーションやユースケースに有用です。

## ベンチマーク結果

OpenSearch Benchmark を使用して、Faiss HNSW を使用した float ベクトルとバイトベクトル間の再現率、インデックス作成、検索パフォーマンスを比較するベンチマークテストを人気のあるデータセットで実行しました。

**注意**: SIMD 最適化 (AVX2 や NEON など) がない場合、または AVX2 が無効になっている場合 (x86 アーキテクチャ)、量子化プロセスにより追加のレイテンシが発生します。

### 設定

以下の表は、ベンチマークテストのクラスター設定を示しています。

| `m` | `ef_construction` | `ef_search` | レプリカ | プライマリシャード | インデックスクライアント |
| --- | --- | --- | --- | --- | --- |
| 16 | 100 | 100 | 0 | 8 | 16 |

以下の表は、ベンチマークテストのデータセット設定を示しています。

| データセット ID | データセット | ベクトル次元 | データサイズ | クエリ数 | 空間タイプ |
| --- | --- | --- | --- | --- | --- |
| **データセット 1** | gist-960-euclidean | 960 | 1,000,000 | 1,000 | L2 |
| **データセット 2** | cohere-ip-10m | 768 | 10,000,000 | 10,000 | innerproduct |
| **データセット 3** | cohere-ip-1m | 768 | 1,000,000 | 10,000 | innerproduct |
| **データセット 4** | sift-128-euclidean | 128 | 1,000,000 | 10,000 | L2 |

### 再現率、メモリ、インデックス作成結果

| データセット ID | Faiss HNSW recall@100 | Faiss HNSW byte recall@100 | 再現率の減少 % | Faiss HNSW メモリ使用量 (GB) | Faiss HNSW byte メモリ使用量 (GB) | メモリ削減 % | Faiss HNSW 平均インデックススループット (docs/sec) | Faiss HNSW byte 平均インデックススループット (docs/sec) | インデックススループット向上 % |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| **データセット 1** | 0.91 | 0.89 | 2.20 | 3.72 | 1.04 | 72.00 | 4673 | 9686 | 107.28 |
| **データセット 2** | 0.91 | 0.83 | 8.79 | 30.03 | 8.57 | 71.46 | 4911 | 10207 | 107.84 |
| **データセット 3** | 0.94 | 0.86 | 8.51 | 3.00 | 0.86 | 71.33 | 6112 | 11673 | 90.98 |
| **データセット 4** | 0.99 | 0.98 | 1.01 | 0.62 | 0.26 | 58.06 | 38273 | 43267 | 13.05 |

### 主な発見

ベンチマーク結果の比較から得られた主な発見は以下の通りです。

* **メモリ削減**: バイトベクトルはメモリ使用量を最大 **72%** 削減し、高次元ベクトルほど大きな削減を達成
* **インデックス作成パフォーマンス**: バイトベクトルの平均インデックススループットは float ベクトルより **2 倍から 107.84%** 高く、特に大きなベクトル次元で顕著
* **検索パフォーマンス**: 検索レイテンシは同等で、バイトベクトルの方が時折優れたパフォーマンスを発揮
* **再現率**: バイトベクトルでは、データセットと使用する量子化技術に応じて、float ベクトルと比較して最大 **8.8%** のわずかな再現率低下

## Faiss は内部的にバイトベクトルをどのように処理するか

Faiss はベクトルストレージの `byte` データ型を直接サポートしていません。これを実現するために、OpenSearch は [`QT_8bit_direct_signed` スカラー量子化器](https://faiss.ai/cpp_api/struct/structfaiss_1_1ScalarQuantizer.html)を使用しています。この量子化器は、符号付き 8 ビット値範囲内の float ベクトルを受け入れ、符号なし 8 ビット整数ベクトルとしてエンコードします。インデックス作成と検索中、これらのエンコードされた符号なし 8 ビット整数ベクトルは、距離計算のために元の符号付き 8 ビットベクトルにデコードされます。

この量子化アプローチにより、メモリフットプリントが 4 分の 1 に削減されます。ただし、スカラー量子化中のエンコードとデコードにより追加のレイテンシが発生します。これを軽減するために、`QT_8bit_direct_signed` 量子化器で [SIMD 最適化](https://opensearch.org/docs/latest/search-plugins/knn/knn-index#simd-optimization-for-the-faiss-engine)を使用して、検索レイテンシを削減し、インデックススループットを向上させることができます。

### 例

以下の例は、`QT_8bit_direct_signed` スカラー量子化器を使用して入力ベクトルがどのようにエンコードおよびデコードされるかを示しています。

```
// 入力ベクトル:
[-126, 28, 127, 0, 10, -45, 12, -110]

// 符号付き int8 を符号なし int8 に変換するために入力ベクトルの各次元に 128 を加算して生成されたエンコードベクトル:
[2, 156, 255, 128, 138, 83, 140, 18]

// 距離計算のために各次元から 128 を減算して元の符号付き int8 ベクトルにデコード:
[-126, 28, 127, 0, 10, -45, 12, -110]
```

## 今後の機能強化

将来のバージョンでは、`4x` Faiss 圧縮レベルの `on_disk` モードを追加してこの機能を強化する予定です。このモードは `fp32` ベクトルを入力として受け入れ、オンライントレーニングを実行し、データをバイトサイズのベクトルに量子化するため、外部量子化を実行する必要がなくなります。

## まとめ

OpenSearch 2.17 では Faiss バイトベクトルのサポートが導入され、量子化されたバイトベクトル埋め込みを効率的に保存できるようになりました。これにより、メモリ消費を最大 75% 削減し、コストを下げ、高いパフォーマンスを維持できます。これらの利点により、バイトベクトルは大規模な類似性検索アプリケーション、特にメモリリソースが限られている場合や、符号付きバイト値範囲内の大量のデータを処理するアプリケーションに最適な選択肢となります。
