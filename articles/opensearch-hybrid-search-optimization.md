---
title: "[翻訳] ハイブリッド検索の最適化"
emoji: "🔬"
type: "tech"
topics: ["opensearch", "検索", "機械学習", "ハイブリッド検索", "セマンティック検索"]
published: true
publication_name: "opensearch"
published_at: 2024-12-30
---

:::message
本記事は [OpenSearch Project Blog](https://opensearch.org/blog/) に投稿された以下の記事を日本語に翻訳したものです。
:::

https://opensearch.org/blog/hybrid-search-optimization/

## はじめに

[ハイブリッド検索は、テキスト検索とニューラル検索を組み合わせて検索の関連性を向上させます](https://opensearch.org/docs/latest/search-plugins/hybrid-search)。この組み合わせは、さまざまな業界や[ベンチマーク](https://opensearch.org/blog/semantic-science-benchmarks/)で有望な結果を示しています。

OpenSearch 2.18 では、[ハイブリッド検索](https://opensearch.org/docs/latest/search-plugins/hybrid-search/)はテキスト検索 (match クエリ) とニューラル検索 (k-NN) のスコアを算術的に組み合わせます。まずスコアを正規化し、次に 3 つの手法 (算術平均、調和平均、幾何平均) のいずれかで組み合わせます。各手法には重み付けパラメータが含まれます。

検索パイプラインの設定は、OpenSearch ユーザーがスコアの正規化、組み合わせ、重み付けを定義する方法です。

## 適切なハイブリッド検索設定を見つけることは難しい

OpenSearch でハイブリッド検索を使用するユーザーにとっての主な課題は、アプリケーションに適した正規化手法、組み合わせ手法、重み付けパラメータをどのように選択するかです。

最適な設定は、コーパス、ユーザーの行動、アプリケーションドメインに大きく依存するため、万能の解決策はありません。

しかし、この理想的なパラメータセットに到達するための体系的な方法があります。最適なパラメータセットを特定することを「グローバルハイブリッド検索最適化」と呼びます。すべての受信クエリに対して最適なパラメータセットを特定するもので、クエリごとの要因に依存しないため「グローバル」です。まずこのアプローチを説明し、その後クエリごとのシグナルを考慮する動的アプローチに進みます。

## グローバルハイブリッド検索オプティマイザー

ハイブリッド検索の設定をパラメータ最適化問題として扱います。パラメータと組み合わせは以下の通りです。

* 2 つの[正規化手法: `l2` と `min_max`](https://opensearch.org/blog/How-does-the-rank-normalization-work-in-hybrid-search/)
* 3 つの組み合わせ手法: 算術平均、調和平均、幾何平均
* テキスト検索とニューラル検索の重み (0 から 1 の範囲の値)

この知識があれば、試して比較するパラメータの組み合わせのコレクションを定義できます。この道を進むには 3 つのものが必要です。

1. クエリセット: クエリのコレクション
2. 判定: 特定のクエリに対する結果の関連性を示す評価のコレクション
3. 検索品質メトリクス: 検索システムがクエリに対して関連ドキュメントを返す性能を示す数値

### クエリセット

クエリセットはクエリのコレクションです。理想的には、クエリセットには代表的なクエリセットが含まれます。「代表的」とは、このクエリセットに異なるクエリクラスが含まれていることを意味します。

* 非常に頻繁なクエリ (ヘッドクエリ) だけでなく、めったに使用されないクエリ (テールクエリ) も
* ビジネスにとって重要なクエリ
* 異なるユーザー意図クラスを表すクエリ (例: 製品カテゴリの検索、製品カテゴリ + 色の検索、ブランドの検索)
* 個々の検索アプリケーションに応じたその他のクラス

これらの異なるクエリは、ユーザーがシステムに送信するすべてのクエリをキャプチャするクエリログから取得するのが最適です。これらを効率的にサンプリングする方法の 1 つが [Probability-Proportional-to-Size Sampling](https://opensourceconnections.com/blog/2022/10/13/how-to-succeed-with-explicit-relevance-evaluation-using-probability-proportional-to-size-sampling/) (PPTSS) です。この方法は頻度加重サンプルを生成できます。

まず、クエリセット内の各クエリをベースラインに対して実行し、この実験フェーズの開始時点での検索結果品質を判定します。

### 判定

クエリセットが利用可能になったら、次は判定です。判定は、特定のクエリに対して特定のドキュメントがどの程度関連しているかを記述します。判定は 3 つの部分で構成されます: クエリ、ドキュメント、(通常は) 数値評価。

評価はバイナリ (0 または 1、つまり無関係または関連) またはグレード付き (例: 0 から 3、明らかに無関係から明らかに関連) にできます。明示的判定の場合、人間の評価者がクエリとドキュメントのペアをレビューし、これらの評価を割り当てます。一方、暗黙的判定はユーザーの行動から導出されます: ユーザーのクエリと閲覧・クリックされたドキュメント。暗黙的判定は、2010 年代初頭に Web 検索から生まれた[クリックモデル](https://clickmodels.weebly.com/)でモデル化でき、単純なクリックスルー率からより[複雑なアプローチ](https://www.youtube.com/watch?v=wa88XShl7hs)まで多岐にわたります。すべてに制限があり、位置バイアスなどのバイアスへの対処方法が異なります。

最近、第 3 のカテゴリの判定生成が登場しました: LLM-as-a-judge。ここでは GPT-4o のような大規模言語モデルがクエリとドキュメントのペアを判定します。

3 つのカテゴリすべてに異なる長所と短所があります。どれを選択しても、適切な量の判定が必要です。明示的判定の場合、デフォルトの検索結果ページの深さの 2 倍がクエリごとの良い出発点です。したがって、ユーザーに結果ページごとに 24 件の結果を表示する場合、各クエリの最初の 48 件の結果を評価する必要があります。

暗黙的判定にはスケールの利点があります: すでにユーザーイベント (クエリ、閲覧されたドキュメント、クリックされたドキュメントなど) を収集している場合、これらのイベントを判定としてモデル化することで数千の判定を計算できます。

### 検索メトリクス

クエリセットと対応する判定があれば、検索品質メトリクスを計算できます。広く使用されている[検索メトリクスは Precision、DCG、NDCG](https://opensourceconnections.com/blog/2020/02/28/choosing-your-search-relevance-metric/) です。

検索メトリクスは、検索システムの検索結果品質を数値で測定する方法を提供します。各設定のメトリクスを計算し、客観的に比較できます。その結果、どの設定が最高スコアを獲得したかがわかります。

クエリセットの生成、ユーザー行動シグナルに基づく暗黙的判定の作成、またはこれらのシグナルに基づくメトリクスの計算に関するガイダンスとサポートをお探しの場合は、[検索結果品質評価フレームワーク](https://github.com/o19s/opensearch-search-quality-evaluation/)をご確認ください。


### ESCI データセットでベースラインを作成する

すべてのピースを組み合わせて、1 つの特定の例の検索メトリクスを計算しましょう。[ハイブリッド検索オプティマイザーリポジトリ](https://github.com/o19s/opensearch-hybrid-search-optimization/)では [ESCI データセット](https://github.com/amazon-science/esci-data)を使用し、[ノートブック 1〜3](https://github.com/o19s/opensearch-hybrid-search-optimization/tree/main/notebooks) で OpenSearch をハイブリッドクエリを実行するように設定し、ESCI データセットの製品をインデックスし、クエリセットを作成し、ベースラインと想定するテキスト検索設定で各クエリを実行します。ESCI データセットには製品とクエリだけでなく判定も含まれているため、検索メトリクスを計算できます。

ベースラインとして `best_fields` タイプの `multi_match` クエリを選択しました。「ベストゲス」のフィールド重みで異なるデータセットフィールドを検索します。実際のシナリオでは、ベイズ最適化に基づく learning to boost などの手法を使用して、最適なフィールドとフィールド重みの組み合わせを見つけることをお勧めします。

```json
{  
  "_source": {  
    "excludes": [  
      "title_embedding"  
    ]  
  },  
  "query": {  
    "multi_match" : {  
      "type": "best_fields",  
      "fields": [  
        "product_id^100",  
        "product_bullet_point^3",  
        "product_color^2",  
        "product_brand^5",  
        "product_description",  
        "product_title^10"  
      ],  
      "operator":   "and",  
      "query":      query[2]  
    }  
  }  
}
```

クエリセットに到達するために、2 つのランダムサンプルを使用しました: 250 クエリを含む小さいものと 5,000 クエリを含む大きいものです。残念ながら、ESCI データセットにはクエリの頻度に関する情報が含まれていないため、上記の PPTSS のような頻度加重アプローチは除外されます。

以下は、両方のクエリセットのテストセットを独立して実行した結果です。

| メトリクス | ベースライン BM25 – 小 | ベースライン BM25 – 大 |
| --- | --- | --- |
| DCG@10 | 9.65 | 8.82 |
| NDCG@10 | 0.24 | 0.23 |
| Precision@10 | 0.27 | 0.24 |

トレーニングデータセットとテストデータセットを用意するために、クエリセットに 80/20 分割を適用しました。すべての最適化ステップはトレーニングセットのクエリを使用し、検索メトリクスはテストセットに対して計算・比較されます。ベースラインでは、実際のトレーニングが行われないため、テストセットのみのメトリクスを計算しました。

これらの数値が最適化の旅の出発点になります。これらのメトリクスを最大化し、次のステップで最適なグローバルハイブリッド検索設定を探すときにどこまで到達できるかを確認します。

### 最適なハイブリッド検索設定の特定

この出発点から、ハイブリッド検索が提供するパラメータ空間を探索できます。グローバルハイブリッド検索最適化ノートブックは、以下のセットで 66 のパラメータ組み合わせを試します。

* 正規化手法: [`l2`, `min_max`]
* 組み合わせ手法: [`arithmetic_mean`, `harmonic_mean`, `geometric_mean`]
* テキスト検索の重み: [`0.0`, `0.1`, `0.2`, `0.3`, `0.4`, `0.5`, `0.6`, `0.7`, `0.8`, `0.9`, `1.0`]
* ニューラル検索の重み: [`1.0`, `0.9`, `0.8`, `0.7`, `0.6`, `0.5`, `0.4`, `0.3`, `0.2`, `0.1`, `0.0`]

ニューラル検索とテキスト検索の重みは常に合計 1.0 になるため、独立して選択する必要はありません。

これにより、テストする組み合わせは 66 になります: 2 つの正規化手法 × 3 つの組み合わせ手法 × 11 のテキスト/ニューラル検索重みの組み合わせ。

これらの組み合わせごとに、トレーニングセットのクエリを実行します。そのために OpenSearch の[一時検索パイプライン機能](https://opensearch.org/docs/latest/search-plugins/search-pipelines/using-search-pipeline/#using-a-temporary-search-pipeline-for-a-request)を使用し、66 のパラメータ組み合わせすべてのパイプラインを事前に作成する必要がなくなります。

以下は、ハイブリッド検索クエリに使用する一時検索パイプラインのテンプレートです。

```json
"search_pipeline": {  
  "request_processors": [  
    {  
      "neural_query_enricher" : {  
        "description": "one of many search pipelines for experimentation",  
        "default_model_id": model_id,  
        "neural_field_default_id": {  
          "title_embeddings": model_id  
        }  
      }  
    }  
  ],  
  "phase_results_processors": [  
    {  
      "normalization-processor": {  
        "normalization": {  
          "technique": norm  
        },  
        "combination": {  
          "technique": combi,  
          "parameters": {  
            "weights": [  
              lexicalness,  
              neuralness  
            ]  
          }  
        }  
      }  
    }  
  ]  
}
```

`norm` は正規化手法の変数、`combi` は組み合わせ手法の変数、`lexicalness` はテキスト検索の重み、`neuralness` はニューラル検索の重みです。

ハイブリッドクエリのニューラル部分は、モデル `all-MiniLM-L6-v2` を使用して製品のタイトルに基づいて作成されたエンベディングを持つフィールドを検索します。

```json
{  
  "neural": {  
    "title_embedding": {  
      "query_text": query[2],  
      "k": 100  
    }  
  }  
}
```

トレーニングデータセットのクエリを使用して結果を取得し、3 つの検索メトリクス DCG@10、NDCG@10、Precision@10 を計算します。小さいデータセットでは、3 つのメトリクスすべてで最高スコアを獲得するパイプライン設定が 1 つあります。このパイプラインは l2 正規化、算術平均、テキスト検索の重み 0.4、ニューラル検索の重み 0.6 を使用します。

計算されたメトリクスは以下の通りです。

* DCG: 9.99
* NDCG: 0.26
* Precision: 0.29

潜在的に最適なハイブリッド検索パラメータの組み合わせをテストセットに適用し、これらのクエリのメトリクスを計算すると、以下の数値になります。

| メトリクス | ベースライン BM25 – 小 | グローバルハイブリッド検索オプティマイザー – 小 | ベースライン BM25 – 大 | グローバルハイブリッド検索オプティマイザー – 大 |
| --- | --- | --- | --- | --- |
| DCG@10 | 9.65 | 9.99 | 8.82 | 9.30 |
| NDCG@10 | 0.24 | 0.26 | 0.23 | 0.25 |
| Precision@10 | 0.27 | 0.29 | 0.24 | 0.27 |

両方のデータセットのすべてのメトリクスで改善が見られます。ここまでの手順を振り返ると、以下のステップを実行しました。

* ランダムサンプリングでクエリセットを作成
* 判定を生成 (正確には、ESCI データセットの既存の判定のみを使用)
* ベースラインの検索メトリクスを計算
* 複数のハイブリッド検索の組み合わせを試す
* 検索メトリクスを比較

2 つの重要な点に注意してください。

* 体系的なアプローチは他のアプリケーションに転用できますが、実験結果は転用できません。常に自分のデータで評価・実験する必要があります。
* ESCI データセットは 100% の判定カバレッジを提供していません。平均して、クエリごとの上位 10 件の取得結果の約 35% の判定カバレッジが見られました。これにより、ある程度の不確実性が残ります。

改善は、上記のパラメータ値でハイブリッド検索に切り替えると、平均してメトリクスが最適化されることを示しています。しかし、もちろん、この切り替えで恩恵を受けるクエリ (検索品質メトリクスが向上) と恩恵を受けないクエリ (検索品質メトリクスが低下) があります。これは、2 つの検索設定を比較するときにほぼ常に観察できることです。1 つの設定が平均して他を上回っても、すべてのクエリがその設定から恩恵を受けるわけではありません。

以下のチャートは、小さいクエリセットのトレーニングクエリの DCG@10 値を示しています。x 軸は l2 正規化、算術平均、テキスト検索の重み 0.1、ニューラル検索の重み 0.9 の検索パイプライン (設定 A) を表します。y 軸は同一の正規化と組み合わせ手法を持つが重みが入れ替わった検索パイプライン: テキスト検索の重み 0.9、ニューラル検索の重み 0.1 (設定 B) を表します。

![検索設定の比較](/images/opensearch-hybrid-search-optimization/1_search_config_comparison-1024x334.png)

設定 B の検索品質メトリクスの改善が最も大きいクエリは、y 軸上にあるものです: この設定では DCG スコアが 0 です。そして設定 A では 15 を超えるものもあります。

すべてのクエリの検索品質メトリクスを改善しようとすると、次の疑問が生じます: 平均的な改善は良いですが、すべてのクエリに対して 1 つの良い設定ではなく、クエリごとに最適な設定を提供するアプローチを考え出すには、どのようにすればより的を絞った方法でこれに取り組めるでしょうか?


## 動的ハイブリッド検索オプティマイザー

ハイブリッド検索クエリごとに適切な設定を個別に特定することを「動的ハイブリッド検索最適化」と呼びます。この方向に進むために、ハイブリッド検索をクエリ理解の課題として扱います。クエリの特定の特徴を理解することで、クエリの「ニューラル度」を予測するアプローチを開発します。「ニューラル度」は、ハイブリッド検索クエリのニューラル検索の重みを表すために使用されます。

なぜ「ニューラル度」だけを予測し、他のパラメータ値は予測しないのかと疑問に思うかもしれません。グローバルハイブリッド検索オプティマイザー (大きいクエリセット) の結果は、検索設定の大部分が 2 つのパラメータ値を共有していることを示しました: l2 正規化手法と組み合わせ手法としての算術平均です。

検索メトリクス (DCG@10、NDCG@10、Precision@10) ごとの上位 5 つの設定を見ると、15 のパイプラインのうち 5 つだけが代替の正規化手法として `min_max` を持ち、これらの設定のいずれも別の組み合わせ手法を持っていません。

この知識により、l2 正規化と算術平均の組み合わせ手法がデータセット全体で最も適していると仮定します。

これにより、ニューラル検索の重みとテキスト検索の重みのパラメータ値が残ります。一方を予測すれば、予測値を 1 から引くことでもう一方を計算できます。「ニューラル度」を予測することで、1 - 「ニューラル度」で「テキスト度」を計算できます。

仮説を検証するために、いくつかの特徴グループとそのグループ内の特徴を作成しました。その後、機械学習モデルをトレーニングして、クエリの特定の「ニューラル度」に対する期待 NDCG 値を予測しました。

### 特徴グループと特徴

特徴を 3 つのグループに分けます: クエリ特徴、テキスト検索結果特徴、ニューラル検索結果特徴。

* クエリ特徴: これらの特徴はユーザーのクエリ文字列を記述します。
* テキスト検索結果特徴: これらの特徴は、ユーザーのクエリをテキスト検索として実行したときに取得される結果を記述します。
* ニューラル検索結果特徴: これらの特徴は、ユーザーのクエリをニューラル検索として実行したときに取得される結果を記述します。

### クエリ特徴

* 単語数: ユーザーのクエリにはいくつの単語がありますか?
* クエリ長: ユーザーのクエリの長さは? (文字数で測定)
* 数字を含む: クエリに 1 つ以上の数字が含まれていますか?
* 特殊文字を含む: クエリに 1 つ以上の特殊文字 (英数字以外の文字) が含まれていますか?

### テキスト検索結果特徴

* 結果数: テキストクエリの結果数。
* 最大タイトルスコア: 取得された上位 10 件のドキュメントのタイトルの最大スコア。スコアは結果セットごとに個別に計算された BM25 スコアです。つまり、BM25 スコアはインデックス全体ではなく、クエリの取得されたサブセットのみで計算されるため、スコアは互いにより比較可能になり、非常にまれなクエリ用語の高い IDF 値から生じる可能性のある外れ値の影響を受けにくくなります。
* タイトルスコアの合計: 上位 10 件のドキュメントのタイトルスコアの合計 (これも結果セットごとに計算)。取得されたすべての上位 10 件のタイトルがどの程度関連しているかを測定するための集計としてスコアの合計を使用します (平均値ではなく)。BM25 スコアは正規化されていないため、平均ではなく合計を使用することが妥当と思われました。

### ニューラル検索結果特徴

* 最大セマンティックスコア: 取得された上位 10 件のドキュメントの最大セマンティックスコア。これは、クエリとタイトルの類似性に基づいてニューラルクエリで受け取るスコアです。
* 平均セマンティックスコア: BM25 スコアとは対照的に、セマンティックスコアは正規化されており、0 から 1 の範囲です。合計を計算しようとするよりも、平均スコアを使用する方が妥当と思われます。

### 特徴エンジニアリング

グローバルハイブリッド検索オプティマイザーの出力をトレーニングデータとして使用しました。このプロセスの一部として、すべてのクエリを 66 回実行しました: ハイブリッド検索設定ごとに 1 回。各クエリの検索メトリクスを計算したので、クエリごとにどのパイプラインが最も効果的だったか、したがってどの「ニューラル度」(ニューラル検索の重み) が最も効果的だったかがわかります。クエリごとの最適な NDCG@10 値を、理想的な「ニューラル度」を決定するメトリクスとして使用しました。

これにより、250 クエリ (小さいクエリセット) または 5,000 クエリ (大きいクエリセット) と、最高の NDCG@10 値を達成した「ニューラル度」値が残ります。次に、各クエリの 9 つの特徴をエンジニアリングしました。これがトレーニングデータとテストデータを構成します。

### モデルのトレーニングと評価の知見

適切なデータが手元にあれば、さまざまなアルゴリズムを探索し、パターンを特定してアプローチが適切かどうかを評価するために、さまざまなモデルフィッティング設定を実験しました。
比較的シンプルな 2 つのアルゴリズムを使用しました: 線形回帰とランダムフォレスト回帰。
交差検証、正則化を適用し、すべての異なる特徴の組み合わせを試しました。これにより、以下のセクションにまとめられた興味深い知見が得られました。

**データセットのサイズが重要**: 異なるサイズのデータセットで作業すると、モデルのトレーニングと評価においてデータ量が重要であることがわかりました。大きいデータセットは、小さいデータセットと比較して、より小さい二乗平均平方根誤差 (RMSE) を報告しました。大きいデータセットは、交差検証の実行内での RMSE スコアの変動も少なくなりました (つまり、1 つの特徴の組み合わせに対する 1 つの交差検証実行内で RMSE スコアを比較した場合)。

**モデルのパフォーマンスはアルゴリズムによって異なる**: ランダムフォレスト回帰の最良の RMSE スコアは 0.18 で、最良の線形回帰モデルの 0.22 と比較されました (大きいデータセット)。ただし、異なる特徴の組み合わせでした。より複雑なモデル (ランダムフォレスト) の方がパフォーマンスが良いです。ただし、パフォーマンスの向上には、このより複雑なモデルのトレーニング時間が長くなるというトレードオフがあります。

**すべてのグループの特徴の組み合わせが最も低い RMSE を持つ**: 3 つの特徴グループ (クエリ、テキスト検索結果、ニューラル検索結果) すべての特徴を組み合わせると、最も低いエラースコアを達成できます。特徴グループ内の特徴の組み合わせの RMSE スコアを見ると、テキスト検索結果の特徴の組み合わせで作業することが最良の代替手段として機能することがわかります。

これは、本番化を考えるときに特に興味深いです。このようなアプローチを本番環境に導入するということは、クエリ時にクエリごとに特徴を計算する必要があることを意味します。テキスト検索結果の特徴とニューラル検索結果の特徴を取得するには、これらのクエリを実行する必要があり、推論時間の前でも全体的なクエリに大幅なレイテンシが追加されます。

以下の画像は、1 つのグループ内の特徴の組み合わせ (青: ニューラル検索特徴、赤: テキスト結果特徴、緑: クエリ特徴) とグループ間 (紫: すべてのグループの特徴) でランダムフォレスト回帰モデルをフィッティングしたときの、1 つの交差検証実行内の RMSE スコアの分布を示しています。特徴ミックス (紫) が最も低い (最良) スコアで、次にテキスト検索結果特徴のみでのトレーニング (赤) が続きます。

![ランダムフォレストの最良の特徴の組み合わせ](/images/opensearch-hybrid-search-optimization/2_random_forest_best_feature_combinations-1024x745.png)

線形モデルの数値を見ても、全体像は変わりません。

![線形モデルの最良の特徴の組み合わせ](/images/opensearch-hybrid-search-optimization/3_linear_model_best_feature_combinations-1024x745.png)

### モデルのテスト

トレーニングされたモデルをテストセットに動的に適用したときのパフォーマンスを見てみましょう。
テストセットの各クエリについて、特徴をエンジニアリングし、「ニューラル度」もモデルに渡す特徴であるため、0.0 から 1.0 の間の「ニューラル度」値に対してモデルに推論させます。次に、最高の予測 (最良の NDCG 値) をもたらした「ニューラル度」値を取得します。「ニューラル度」がわかれば、「ニューラル度」を 1 から引くことで「テキスト度」を計算できます。

グローバルハイブリッド検索オプティマイザーの実験で最高スコアを獲得したため、ハイブリッド検索の正規化と組み合わせのパラメータ値として l2 正規化と算術平均を再び使用します。これにより、ハイブリッドクエリを構築し、実行し、結果を取得し、ベースラインやグローバルハイブリッド検索オプティマイザーと同様に検索メトリクスを計算します。

以下は小さいデータセットのメトリクスです。

| メトリクス | ベースライン BM25 | グローバルハイブリッド検索オプティマイザー | 動的ハイブリッド検索オプティマイザー – 線形モデル | 動的ハイブリッド検索オプティマイザー – ランダムフォレストモデル |
| --- | --- | --- | --- | --- |
| DCG@10 | 9.65 | 9.99 | 10.92 | 10.92 |
| NDCG@10 | 0.24 | 0.26 | 0.28 | 0.28 |
| Precision@10 | 0.27 | 0.29 | 0.32 | 0.32 |

以下は大きいデータセットのメトリクスです。

| メトリクス | ベースライン BM25 | グローバルハイブリッド検索オプティマイザー | 動的ハイブリッド検索オプティマイザー – 線形モデル | 動的ハイブリッド検索オプティマイザー – ランダムフォレストモデル |
| --- | --- | --- | --- | --- |
| DCG@10 | 8.82 | 9.30 | 10.13 | 10.13 |
| NDCG@10 | 0.23 | 0.25 | 0.27 | 0.27 |
| Precision@10 | 0.24 | 0.27 | 0.29 | 0.29 |

これらの数値を見ると、ベースラインから始まり、クエリごとの「テキスト度」と「ニューラル度」の動的予測まで、着実にプラスの傾向が見られます。大きいデータセットでは DCG が 8.9% 増加し (9.3 から 10.13 に上昇)、小さいデータセットでは 9.3% 増加しています。他のメトリクスも増加しています: NDCG は大きいデータセットで 7.4%、小さいデータセットで 10.3% の改善を示し、Precision は大きいデータセットで 8%、小さいデータセットで 7.7% の改善を示しています。

興味深いことに、両方のモデルはまったく同じスコアを獲得しています。その理由は、両方が異なる NDCG 値を予測しますが、入力特徴として同じ「ニューラル度」で最良のものを予測するためです。したがって、モデルは評価フェーズで RMSE スコアが異なる場合がありますが、テストセットに適用すると同等の結果を提供します。

判定カバレッジが低いにもかかわらず、すべてのメトリクスで改善が見られます。これにより、このアプローチがテキスト検索からハイブリッド検索に切り替える検索システムだけでなく、すでに本番環境にあるが最適な設定を評価・特定するための体系的なプロセスを使用したことがないシステムにも価値を提供できるという確信が得られます。

## まとめ

OpenSearch の現在の状態と機能 (正規化と組み合わせ手法) に基づいて、ハイブリッド検索を最適化するための体系的なアプローチを提供します。ESCI データセットが提供する低い判定カバレッジを考慮しても、結果は有望に見えます。

皆さんがこのアプローチを採用し、自分のデータセットでその有用性を探求することをお勧めします。提供されたアプローチに関するコミュニティからのフィードバックを [OpenSearch フォーラム](https://forum.opensearch.org/)でお待ちしています。

## 今後の作業

現在計画されている次のステップには、より高い判定カバレッジを持ち、異なるドメインをカバーするデータセットでアプローチを再現し、その一般化可能性を判断することが含まれます。

ハイブリッド検索の最適化は、通常、検索結果品質の最適化の最初のステップではありません。テキスト検索結果を最初に最適化することが特に重要です。なぜなら、テキスト検索クエリはハイブリッド検索クエリの一部だからです。ベイズ最適化は、最適なフィールドとフィールド重みのセットを効率的に特定するための効率的な手法であり、「learning to boost」とも呼ばれることがあります。

66 の異なる組み合わせを試す単純なアプローチは、ベイズ最適化のような手法を適用することで、よりエレガントに実行できます。特に、大規模な検索インデックスと多数のクエリに対してパフォーマンスの向上が期待されます。

Reciprocal Rank Fusion は、現在活発に開発中であり、テキスト検索とニューラル検索を組み合わせる別の方法です。

* <https://github.com/opensearch-project/neural-search/issues/865>
* <https://github.com/opensearch-project/neural-search/issues/659>

この手法も含め、クエリごとに動的にハイブリッド検索を実行する最良の方法を特定する予定です。
