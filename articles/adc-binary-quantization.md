---
title: "[翻訳] バイナリ量子化のための非対称距離計算"
emoji: "🔍"
type: "tech"
topics: ["opensearch"]
published: true
publication_name: opensearch
published_at: 2025-11-26
---

:::message
この記事は [OpenSearch Project の公式ブログ記事](https://opensearch.org/blog/asymmetric-distance-computation-for-binary-quantization/) の日本語翻訳です。
:::

https://opensearch.org/blog/asymmetric-distance-computation-for-binary-quantization/

現代の検索拡張生成 (RAG) セットアップでは、通常、非常に高次元のクエリベクトルの k 近傍を大規模なベクトルデータセットから検索します。これらのデータセットが大きくなりすぎると、すべてのベクトルをメモリに保存することは法外に高価になる可能性があります。ベクトルの保存に使用される総メモリは次のようになります。

```
total_bits = num_documents × data_dimensionality × bits_per_dimension
```

これは、各ベクトルの各次元の値をエンコードするために使用されるビット数に線形に依存します。ドキュメント数や次元数を安全に削減することが困難または不十分な場合、メモリフットプリント (およびそれによる手頃な価格) を削減する一般的なアプローチの 1 つは、各ベクトルの表現を標準の `float32` 表現から 32 ビット未満に削減することです。

最も直接的な圧縮戦略である**スカラー量子化**は、代替の浮動小数点表現を使用することで圧縮を実現します。たとえば、`float16` 表現に切り替えると、メモリ使用率が 50% 削減されます (つまり、2 倍のデータ圧縮)。これで十分な場合もありますが、データセットを RAM に収めるためにより高い圧縮が必要な状況もあります。最も極端なスカラー量子化アプローチである**バイナリ量子化**は、すべての float を 1 ビットに削減し、32 倍の圧縮を実現し、メモリの式を次のように簡素化します。

```
total_bits = num_documents × data_dimensionality
```

削減の規模を説明すると、1 億個の異なる 768 次元ベクトルのデータセットは、`float32` ベクトルを使用する場合 300 GB 以上のシステムメモリを必要としますが、バイナリ量子化された対応物は 10 GB 未満に快適に収まります。

当然のことながら、これらのメモリ削減には 1 つの大きな欠点があります。それは**リコールの低下**です。これらのベクトルを圧縮すればするほど、それらの真の表現間の距離を推定することが難しくなります。これにより、特定のクエリに対する真の k 近傍を特定することがより困難になります。この欠点の一部は根本的に避けられませんが、データ圧縮の悪影響を最小限に抑えるためのさまざまな技術が発見されています。このブログ記事では、主にそのようなアプローチの 1 つである**非対称距離計算 (ADC)** に焦点を当てます。これにより、圧縮されていないクエリを使用して圧縮されたインデックスを検索し、従来のバイナリ量子化と比較して改善されたリコールで 32 倍の圧縮を実現できます。

## バイナリ量子化の仕組み

各次元をエンコードするために 1 ビットしかない場合、バイナリ量子化されたベクトルは各次元に 2 つの値のいずれかのみを割り当てることができ、通常は ±1 として解釈されます。バイナリ量子化を使用して量子化するには、最も簡単な方法は元のベクトルの要素ごとの符号を取ることです。負の値は -1 (バイナリで `0` としてエンコード) にマップされ、正の値は +1 (バイナリで `1` としてエンコード) にマップされます。

実際には、通常、最初にベクトルを**平均中心化**する方が良いです。つまり、データセット (座標ごと) の平均を減算することで、データセットを原点に向かってシフトします。次に、元のベクトルではなく、これらのシフトされたベクトルに量子化が適用されます。これは、特に一部 (またはすべて!) の座標が同じ符号を取る可能性があるデータセットで、元のベクトルに関する情報を保持するのに役立ちます。たとえば、SIFT データセットのすべてのベクトルには非負の値のみがあります。平均中心化がなければ、すべてのポイントはすべて 1 のベクトルにバイナリエンコードされます。平均中心化により、データはより広範なバイナリ表現を使用して表現されます。

シフトと量子化のプロセスを次の図に示します。

![平均中心化](/images/adc-binary-quantization/Mean-Centering.png)
_図: ドキュメントコーパスのバイナリ量子化を計算するには、まずデータを平均中心化して、平均ドキュメントベクトルが原点に位置するようにし、次に各座標をその符号に応じて ±1 の値に変換します。_

2 次元では 4 つの可能な量子化しか許可されませんが (したがって、多くのベクトルが必然的に同じ値に量子化されます)、より高い _d_ 次元空間では、バイナリ量子化の数は通常、コーパスのサイズを大幅に超えます。したがって、典型的な高次元データセットは、比較的少数の衝突を持つ傾向があります。各ドキュメントについて、完全精度のベクトルをディスクに保存し、バイナリ量子化されたベクトルのみを RAM に保存します。

バイナリ量子化の仕組みを理解したので、これらの圧縮されたベクトルを使用して k-NN 検索を実行する 2 つの異なる方法を見てみましょう。**対称距離計算 (SDC)** と**非対称距離計算 (ADC)** です。

### 対称距離計算

バイナリ量子化されたインデックスで k-NN 検索を実行する古典的な方法は、前述とまったく同じ手順を使用してクエリベクトルを量子化することから始まります。クエリベクトルを量子化することで、RAM に保存されている量子化されたデータセットと同じスケールとデータ型を持つことが保証され、クエリベクトルとドキュメントベクトル間の距離を評価するプロセスが大幅に簡素化されます。

例として、2 つの 4 次元ベクトル $\vec{v}_1=(+1,-1,+1,-1)$ と $\vec{v}_2=(-1,-1,+1,+1)$ の間のユークリッド距離の二乗を計算してみましょう。古典的な方法で計算すると、この操作には合計 11 の操作が含まれます。4 つの減算、4 つの二乗、および 3 つの加算操作です。

$$
\begin{align*}
\|\vec{v}_1-\vec{v}_2\|_2^2&=(+1-(-1))^2+((-1)-(-1))^2+((+1)-(+1))^2+((-1)-(+1))^2\\
&=2^2+0^2+0^2+(-2)^2\\
&=4+0+0+4\\
&=8
\end{align*}
$$

ただし、この計算は別の方法でも表現できます。ユークリッド距離の二乗は、$\vec{v}_1$ が $\vec{v}_2$ と異なる座標の数の正確に 4 倍であり、これは**ハミング距離**としても知られています。したがって、$\vec{v}_1$ と $\vec{v}_2$ の間のユークリッド距離の二乗を、それらのバイナリ表現が異なる座標の数の 4 倍として同等に計算できます。

最新のプロセッサは、完全な 64 ビットワードに対して一度に `xor` (「これらのビット文字列はどこで異なるか?」に答える) および `popcount` (「このビット文字列に 1 がいくつあるか?」に答える) 操作を実行できるため (または SIMD 拡張を使用するとさらに多く)、バイナリ量子化は多くの次元からの寄与を並列に計算できるため、距離計算の複雑さを同様に大きな係数で削減します。

SDC の欠点は、**リコール** (検索アルゴリズムによって返される真の k 近傍の割合) への影響です。結局のところ、すべてのベクトルがすべての次元で同時に徹底的に歪められている場合、常に最も近いベクトルを特定できるとは期待できません。

![SDC の歪み](/images/adc-binary-quantization/SDC-Distortion.png)
_図: 中心化後のクエリベクトル (オレンジ色の四角) は、元々紫色のドキュメントベクトルよりも青色のドキュメントベクトルにはるかに近い位置にあります。ただし、対称量子化がすべてのベクトルを各座標で ±1 にマップした後、この情報は失われ、オレンジ色のクエリベクトルは対応する量子化されたドキュメントベクトルのそれぞれから等距離に見えます。_

次のセクションでは、ADC を使用してこの弱点がどのように対処されるかを説明します。

### 非対称距離計算

SDC を考慮すると、アルゴリズムがプロセスの 2 つの異なるポイントで距離計算にエラーを導入したことに注意してください。まず、コーパス内のドキュメントベクトルが量子化されて、バイナリ量子化が提供する 32 倍のメモリ削減が実現されます。次に、クエリベクトルも量子化されたドキュメントのスケールとデータ型に一致するように量子化されます。

ただし、この 2 番目の量子化は、k-NN 検索のメモリ消費を意味のある形で削減するものではありません。非常に高次元のデータセットでも、量子化されていないクエリのフットプリントは通常、数キロバイト程度です。ADC では、クエリベクトルを元の量子化されていない形式で保持しながら、バイナリ量子化されたドキュメントベクトルと比較することでリコールが改善されます。この非対称性、つまり一方のベクトルを高精度に保ちながら、もう一方をバイナリのままにすることで、元の距離関係に関するより多くの情報を保持できます。

ADC が克服する主な困難は、バイナリ量子化が、平均中心化後に同じ符号を持つ限り、次元内のすべての値を同一に扱うことです。これは、元の大きさに潜在的に大きな違いがあるにもかかわらずです。たとえば、平均中心化後、+0.6 の大きな正の値と +0.1 の小さな正の値は、元の空間で非常に異なる値を表しているにもかかわらず、両方とも +1 に量子化されます。逆に、それ以外は非常に近い -0.1 と +0.1 は、元の空間でほぼ同一であるにもかかわらず、反対の値に量子化されます。

ADC は、クエリベクトルを完全精度の形式で保持しながら、ドキュメントベクトルに一致するようにスケーリングすることで、この制限に対処します。量子化されたクエリではなく、再スケーリングされたクエリをバイナリドキュメントベクトルと直接比較することで、クエリも量子化された場合に失われる元のクエリベクトルの微妙な変動がより適切にキャプチャされます。

![ADC のメイン](/images/adc-binary-quantization/ADC-Main.png)
_図: ADC の場合、ドキュメントベクトルは SDC と同じように量子化されます。ただし、クエリベクトルは完全な FP32 精度で保持され、±1 の値に量子化する必要はありません。_

#### ADC の再スケーリング

クエリベクトルを元の精度で維持していても、量子化されたドキュメントベクトルと同じスケールで動作することを保証する必要があります。バイナリ量子化は、各次元の初期の大きさに関係なく、すべての値を ±1 にマップし、それによってデータの暗黙的な再スケーリングを誘発することを思い出してください。距離計算が意味を持つためには、クエリベクトルもドキュメント量子化中に使用されたのと同じデータセット平均を使用して再中心化され、バイナリ量子化のスケールに一致するように再スケーリングされる必要があります。

次の図は、再スケーリングに失敗すると ADC が間違った最近傍を見つける例を示しています。最近傍ドキュメントが元の空間で近い場合でも (左上の象限の赤い点)、量子化後は遠くの点 (右上の象限の青い点) よりも遠くに見える可能性があります。再スケーリングにより、相対的な近さができるだけ保持されるように完全精度のクエリベクトルを再配置しようとします。

![ADC 再スケーリングの重要性](/images/adc-binary-quantization/ADC-Rescaling-Importance-scaled.png)
_図: クエリの再スケーリングが最近傍検索に与える影響。ドキュメント量子化は、本質的にドキュメントベクトルに一種の座標再スケーリングを適用します。クエリの再スケーリングがないと、クエリの近くの一部のポイントがそこから遠ざけられる可能性があり、クエリから遠いポイントが近づけられる可能性があります。クエリの再スケーリングは、ドキュメントベクトルの再配置の影響を打ち消すためにクエリベクトルを更新します。_

クエリの適切なスケールを特定するために、データセットの各次元で「典型的な」ドキュメントがどのように歪められたかを調べます。データインデックス作成時に、データセットの各次元 $i$ に対して 2 つの重心を計算します。

1. $\vec{l}_i$ は、-1 に量子化されたすべての値の次元 $i$ の平均です
2. $\vec{h}_i$ は、+1 に量子化されたすべての値の次元 $i$ の平均です

![ADC 再スケーリング戦略](/images/adc-binary-quantization/ADC-Rescaling-Strategy.png)

_図: 各次元について、-1 ($\vec{l}_i$ の場合) と +1 ($\vec{h}_i$ の場合) のそれぞれに量子化される平均値を計算します。左の図では、x 次元で負または正に量子化されたものの平均として $\vec{l}_x$ と $\vec{h}_x$ の値を計算します。同様に、右のサブ図は、y 次元の正対負の量子化された値の平均を調べることで $\vec{l}_y$ と $\vec{h}_y$ を計算します。_

これらの重心は、その次元の 2 つの量子化バケットのいずれかに入る「平均」値を表します。バイナリ量子化により、量子化後、各次元の正に量子化された値と負に量子化された値の差は正確に 2 になります。ADC でこの特性を再現するには、スケーリング後の重心間の平均距離も 2 になるようにデータをスケーリングします。つまり、クエリベクトル v を新しい v' に再スケーリングします。

$$
\vec{v}_i'=2\frac{\vec{v}_i-\vec{l}_i}{\vec{h}_i-\vec{l}_i}-1
$$

$\vec{v}_i=\vec{l}_i$ の場合は常に $\vec{v}_i'=-1$ であり、$\vec{v}_i=\vec{h}_i$ の場合は常に $\vec{v}_i'=+1$ であることに注意してください。$\vec{v}_i$ の他のすべての値について、このスケーリングは -1 と +1 の間を補間し、$\vec{v}_i$ が次元 $i$ の両方の重心よりも小さいか大きい場合、これらの境界の外側に落ちる可能性があります。この再スケーリングされたクエリベクトル $v'$ を使用して、SDC のようにバイナリ量子化されたクエリで達成可能なものよりも高い忠実度でバイナリ量子化されたドキュメントベクトルへのユークリッド距離を計算する準備が整いました。

1 つの利点は、重心情報はデータセット全体に対して 1 回だけ計算する必要があり、ドキュメントベクトル自体と比較して無視できる追加のストレージしか必要としないことです (2 つの完全精度ベクトルに匹敵)。さらに、クエリ時には、コーパス内のすべてのドキュメントベクトルと比較する前に、クエリベクトルに 1 回だけ再スケーリングを適用する必要があります。

## 本番環境での ADC の使用

Amazon OpenSearch Service で ADC を使用したインデックスの作成を有効にするには、インデックスの作成時に `enable_adc` を `true` に設定します。

```json
PUT /vector-index
{
  "settings" : {
    "index": {
      "knn": true
    }
  },
  "mappings": {
    "properties": {
      "vector_field": {
        "type": "knn_vector",
        "dimension": 8,
        "method": {
            "name": "hnsw",
            "engine": "faiss",
            "space_type": "l2",
            "parameters": {
              "encoder": {
                "name": "binary",
                "parameters": {
                  "bits": 1,
                  "enable_adc": true
                }
              }
            }
        }
      }
    }
  }
}
```

ADC を有効にしてインデックスを作成すると、標準の OpenSearch クエリ構文を使用して k-NN 検索を実行できます。ADC の最適化は検索操作中に自動的に行われます。

## まとめ

ADC は、ベクトル検索の最適化における重要な進歩を表しており、完全精度のベクトルと比較してメモリ使用量を 32 分の 1 に削減しながら、SDC に通常関連するリコールの低下を大幅に軽減します。この技術は、大規模なベクトル検索における重要な課題、つまりメモリ効率と検索品質のバランスを取ることに対処します。OpenSearch 3.2 以降、ADC を使用して、結果の関連性を損なうことなくベクトル検索の実装を最適化できます。

OpenSearch デプロイメントで ADC を試して、[OpenSearch コミュニティフォーラム](https://forum.opensearch.org/) で経験を共有することをお勧めします。皆様のフィードバックは、ベクトル検索機能の継続的な改善を推進するのに役立ちます。

## 著者について

- **Tal Wagner** は、OpenSearch Project と Amazon OpenSearch Service に取り組んでいる AWS のシニア応用科学者です。2020 年に MIT の CSAIL でコンピュータサイエンスの博士号を取得しました。彼の関心には、大規模データセットのアルゴリズム設計と大規模機械学習が含まれます。

- **Finn Roblin** は、OpenSearch ベクトル検索に取り組んでいるソフトウェアエンジニアです。彼の関心には、大規模機械学習、推薦システム、トライアスロンスポーツ科学が含まれます。

- **Yonatan Naamad** は、OpenSearch Project に取り組んでいる AWS のシニア応用科学者です。2017 年にプリンストン大学でコンピュータサイエンスの博士号を取得しました。彼の関心には、グラフアルゴリズムと機械学習が含まれます。
