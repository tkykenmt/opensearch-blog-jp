---
title: "[翻訳] OpenSearch における MCP の紹介"
emoji: "🔍"
type: "tech"
topics: ["opensearch", "mcp", "ai", "agent"]
  - "mcp"
  - "opensearch"
publication_name: "opensearch"
published: true
published_at: "2025-05-16 16:19"
---

:::message
本記事は [OpenSearch Project Blog](https://opensearch.org/blog/) に投稿された以下の記事を日本語に翻訳したものです。
:::

https://opensearch.org/blog/introducing-mcp-in-opensearch/

[Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction) は、AI エージェントと外部ツール間の統合の複雑さを軽減する標準化された通信フレームワークです。MCP がなければ、各ツール統合に特定の API エンドポイント、パラメータスキーマ、レスポンス形式、エラー処理パターンのためのカスタムコードの実装が必要となるため、大きな技術的オーバーヘッドに直面する可能性があります。この断片化はメンテナンスの課題を生み出し、開発速度を低下させます。MCP はツールの発見、パラメータ検証、レスポンス形式、エラー処理のための一貫したインターフェースを持つ統一されたプロトコル層を提供することでこれらの問題に対処します。このプロトコルは AI アプリケーションとツールプロバイダーのサーバー間の契約を確立し、標準化された JSON ペイロードと明確に定義された動作の期待値を通じてシームレスな相互運用性を可能にします。この標準化により、エージェントは各ツールの独自の API 構造に適応するのではなく、一貫した MCP インターフェースとのみ通信すればよいため、最小限のコード変更で新しいツールを統合できます。

以下は 2 つのアプローチの比較です。左側では、エージェントが各ツールに直接接続し、すべての接続にカスタム統合が必要です。右側では、大規模言語モデル (LLM) が MCP を使用して公開されたツールに接続します。MCP は中間層として機能し、通信を簡素化し、よりクリーンでスケーラブルなアーキテクチャを実現します。

左側に複数のワイヤーを持つ混乱した男性の絵があり、右側には解決策として 1 本のケーブルが示されています。

![](https://storage.googleapis.com/zenn-user-upload/0cfcbb361868-20250516.png)

## セクション 1: OpenSearch MCP サーバー

OpenSearch は MCP サーバーを実行するための 2 つの方法を提供しています。バージョン 3.0 からの[組み込みオプション](https://github.com/opensearch-project/project-website/blob/0e20f3758d60e8a3ace09add9d13a58a6b471947/_posts/2025-05-05-Introducing-MCP-in-OpenSearch.md#section-11-built-in-mcp-server)と、以前のバージョンまたは外部デプロイメント用の[スタンドアロンオプション](https://github.com/opensearch-project/project-website/blob/0e20f3758d60e8a3ace09add9d13a58a6b471947/_posts/2025-05-05-Introducing-MCP-in-OpenSearch.md#section-12-standalone-opensearch-mcp-server)です。

### セクション 1.1: 組み込み MCP サーバー

OpenSearch 3.0 は ML Commons プラグインの一部として実験的な MCP サーバーを提供しています。このサーバーは、ストリーミング Server-Sent Events (SSE) インターフェース (/\_plugins/\_ml/mcp/sse) を介して、コアツールセットをファーストクラスの MCP エンドポイントとして公開します。LLM エージェント（例えば、LangChain の ReAct エージェント）は、サーバーに接続し、提供されるツールを発見し、JSON 引数を使用してツールを呼び出すことができます。カスタムアダプターコードや追加の REST エンドポイントは必要ありません。

OpenSearch MCP サーバーは、エージェントに検索データへの安全でリアルタイムなアクセスを提供するラストマイル問題を解決します。実際には、クラスター内のすべてのインデックス (製品カタログ、ログ、ベクトルストアなど) が、以下の図に示すように、MCP サーバーを使用して好みのエージェントフレームワークによって照会、要約、または相互参照できることを意味します。

![](https://storage.googleapis.com/zenn-user-upload/2d9ca9eda509-20250516.png)

API ドキュメントと実装の詳細については、[MCP サーバー API ドキュメント](https://docs.opensearch.org/docs/latest/ml-commons-plugin/api/mcp-server-apis/index/)をご覧ください。

組み込みサーバーを使用する主な利点は以下のとおりです。

- 統合データプラットフォーム統合: AI エージェントが検索、分析、ベクトルストア操作をシームレスに実行できるネイティブ機能を提供します。
- 合理化されたインフラストラクチャ: OpenSearch に完全に統合されており、別の MCP サーバーをデプロイ、ホスト、または維持する必要はありません。
- エンタープライズグレードのセキュリティ: 認証に OpenSearch セキュリティを使用し、ツール全体で一貫したアクセス制御を強制します。
- 開発効率の向上: すべてのツールに標準インターフェースを提供し、カスタム統合コードの必要性を排除します。
- フレームワークの柔軟性: LangChain、Bedrock などの主要な AI フレームワークと連携します。

### クイックスタート

OpenSearch で組み込み MCP サーバーをセットアップするには、以下の手順に従います。

ステップ 1: SSE をサポートするための実験的ストリーミング機能を有効にする

[ドキュメント](https://docs.opensearch.org/docs/latest/install-and-configure/configuring-opensearch/network-settings/#selecting-the-transport)の手順に従って、transport-reactor-netty4 プラグインをインストールし、実験的ストリーミングを有効にします。

ステップ 2: 実験的 MCP サーバーを有効にする

```
PUT /_cluster/settings/
{
    "persistent": {
        "plugins.ml_commons.mcp_server_enabled": "true"
    }
}
```

ステップ 3: ツールを登録する

サーバーが起動すると、ツールは公開されません。公開したいツールを登録できます。以下は ListIndexTool と SearchIndexTool をアクティブにする基本的な例です。

```
POST /_plugins/_ml/mcp/tools/_register
{
    "tools": [
        {
            "type": "ListIndexTool"
        },
        {
            "type": "SearchIndexTool",
            "attributes": {
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "input": {
                            "index": {
                                "type": "string",
                                "description": "OpenSearch index name. for example: index1"
                            },
                            "query": {
                                "type": "object",
                                "description": "...",
                                "additionalProperties": false
                            }
                        }
                    }
                },
                "required": [
                    "input"
                ],
                "strict": false
            }
        }
    ]
}
```

これで完了です！ListIndexTool と SearchIndexTool が MCP サーバーで使用できるようになりました。

重要なエンドポイント:

- MCP サーバーのベース URL: /\_plugins/\_ml/mcp
- MCP クライアントによって内部的に使用されるメッセージエンドポイント: /\_plugins/\_ml/mcp/sse/message?sessionId=...

注: Python MCP クライアントの場合、接続を確立するには次の URL を使用します。/\_plugins/\_ml/mcp/sse?append_to_base_url=true

### 利用可能なツール

OpenSearch は、OpenSearch MCP サーバーに登録できる包括的なツールスイートを提供しています。サポートされているツールのリストについては、[ツール](https://docs.opensearch.org/docs/latest/ml-commons-plugin/agents-tools/tools/index/)をご覧ください。

### 認証

MCP サーバーに接続する際には、OpenSearch のセキュリティ設定に基づいて適切な認証ヘッダーを含める必要があります。以下の例は、LangChain クライアントにヘッダーを追加する方法を示しています。

```python
cred = base64.b64encode(f"{username}:{password}".encode()).decode()
headers = {
    "Content-Type": "application/json",
    "Accept-Encoding": "identity",
    "Authorization": f"Basic {cred}"
}

client = MultiServerMCPClient({
    "opensearch": {
        "url": "http://localhost:9200/_plugins/_ml/mcp/sse?append_to_base_url=true",
        "transport": "sse",
        "headers": headers
    }
})
```

### LangChain を使用したエンドツーエンドの例

この短いスクリプトは LangChain エージェントを初期化し、利用可能な MCP ツールを検出し、エージェントにクラスター内のすべてのインデックスをリストするよう依頼します。この例では gpt-4o を使用していますが、このスクリプトは LangChain およびツール呼び出しと統合されるあらゆる LLM と互換性があります。

```python
import asyncio
from dotenv import load_dotenv
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain_openai import ChatOpenAI
from langchain.agents import AgentType, initialize_agent

# .env ファイルから openAI キーを読み込む
load_dotenv()

# OpenAI チャットモデルを初期化
model = ChatOpenAI(model="gpt-4o")

async def main():
    # OpenSearch 接続詳細を持つ MCP クライアントを作成
    async with MultiServerMCPClient({
        "opensearch": {
        "url": "http://localhost:9200/_plugins/_ml/mcp/sse?append_to_base_url=true",
        "transport": "sse",
        "headers": {
            "Content-Type": "application/json",
            "Accept-Encoding": "identity",  # SSE の圧縮を無効化
        }
    }
    }) as client:
        # MCP サーバーから利用可能なツールを取得
        tools = client.get_tools()

        # ツールとモデルで LangChain エージェントを初期化
        agent = initialize_agent(
            tools=tools,
            llm=model,
            agent=AgentType.OPENAI_FUNCTIONS,
            verbose=True,
        )

        # 製品をリストするクエリでエージェントを実行
        await agent.ainvoke({"input": "List all the products"})

if __name__ == "__main__":
    asyncio.run(main())
```

OpenSearch のサンプル製品インデックスで実行すると、エージェントはインテリジェントなツールの使用を実証します。まず、ListIndexTool を呼び出して利用可能なインデックスを検出し、次に products インデックスで SearchIndexTool を使用して製品情報を取得し、構造化された形式で提示します。このワークフローは、LLM が MCP ツールを通じて OpenSearch データを自律的にナビゲートする方法を示しています。

```
> Entering new AgentExecutor chain...
Invoking: `ListIndexTool` with `{'indices': []}`
# ツールは "products" インデックスを含む利用可能なインデックスを見つける

Invoking: `SearchIndexTool` with `{'input': {'index': 'products', 'query': {'query': {'match_all': {}}}}}`
# ツールは製品データを返す

# モデルの最終応答
Here are the products listed in the OpenSearch index:
1. **Product A**: High-quality leather wallet
2. **Product B**: Eco-friendly bamboo toothbrush
...
```

### セクション 1.2: スタンドアロン OpenSearch MCP サーバー

セクション 1.1 で説明した OpenSearch の組み込み MCP サーバーは、バージョン 3.0 以降でのみ利用可能です。以前のバージョンで MCP を使用するには、OpenSearch クラスターの外部でスタンドアロン MCP サーバーを実行できます。

スタンドアロンアーキテクチャは単純なフローを使用します。

1. エージェントがツール呼び出しを開始します。
2. 呼び出しはスタンドアロン MCP サーバーに転送されます。
3. MCP サーバーは OpenSearch クラスターに REST リクエストを行い、必要なデータを取得し、レスポンスをフォーマットし、エージェントに返します。

このフローは以下の図に示されています。

![](https://storage.googleapis.com/zenn-user-upload/cc59ea0c86d0-20250516.png)

この新しいスタンドアロン MCP サーバーはまもなく正式にリリースされますが、[デモバージョン](https://github.com/rithin-pullela-aws/opensearch-mcp-server)をテストできます。スタンドアロン OpenSearch MCP サーバーの詳細については、[RFC](https://github.com/opensearch-project/ml-commons/issues/3749) をご覧ください。

スタンドアロンサーバーを使用する主な利点は以下のとおりです。

- 独立した操作: OpenSearch クラスターの外部の別のプロセスとして実行します。
- 分離されたリリースサイクル: OpenSearch バージョンのリリースとは独立して更新できます。
- 柔軟な通信: エージェント接続のために SSE と stdio の両方のプロトコルをサポートします。
- シームレスな統合: MCP サーバーに接続する Claude for Desktop などのツールと互換性があります。
- 幅広いバージョンサポート: REST API 呼び出しを通じて複数の OpenSearch バージョンと対話します。

### クイックスタート

OpenSearch でスタンドアロン MCP サーバーをセットアップするには、以下の手順に従います。

ステップ 1: デモ PyPI パッケージをインストールする

デモ PyPI パッケージをインストールします（正式リリースはまもなくです）。

```
pip install test-opensearch-mcp
```

ステップ 2: MCP サーバーを起動する

stdio プロトコル（Claude for Desktop に推奨）の場合、次のコマンドを実行します。

```
python -m mcp_server_opensearch
```

SSE プロトコル（ポート 9900 で実行）の場合、次のコマンドを実行します。

```
python -m mcp_server_opensearch --transport sse
```

### 認証方法

MCP サーバーを OpenSearch クラスターに接続するには、環境変数を設定します。

- 基本認証

```
export OPENSEARCH_URL="<your_opensearch_domain_url>"
export OPENSEARCH_USERNAME="<your_opensearch_domain_username>"
export OPENSEARCH_PASSWORD="<your_opensearch_domain_password>"
```

- AWS Identity and Access Management (IAM) ロール認証

```
export OPENSEARCH_URL="<your_opensearch_domain_url>"
export AWS_REGION="<your_aws_region>"
export AWS_ACCESS_KEY="<your_aws_access_key>"
export AWS_SECRET_ACCESS_KEY="<your_aws_secret_access_key>"
export AWS_SESSION_TOKEN="<your_aws_session_token>"
```

### 利用可能なツール

現在、以下のツールが利用可能です。

- ListIndexTool: OpenSearch 内のすべてのインデックスをリストします。
- IndexMappingTool: OpenSearch 内のインデックスのマッピングと設定情報を取得します。
- SearchIndexTool: OpenSearch 内のインデックスをクエリを使用して検索します。
- GetShardsTool: OpenSearch 内のシャードに関する情報を取得します。

ツールの完全なドキュメントについては、[利用可能なツールガイド](https://github.com/rithin-pullela-aws/opensearch-mcp-server/blob/main/README.md#available-tools)をご覧ください。

コミュニティからの貢献を歓迎します! 新しいツールの追加や既存のツールの強化方法については、[開発者ガイド](https://github.com/rithin-pullela-aws/opensearch-mcp-server/blob/main/DEVELOPER_GUIDE.md)をご覧ください。

### Claude for Desktop との統合

Claude for Desktop は stdio プロトコルを通じて MCP をネイティブにサポートしており、統合が簡単です。Claude for Desktop と MCP サーバーを統合するには、以下の手順に従います。

ステップ 1: Claude for Desktop を設定する

- Claude for Desktop で、Settings > Developer > Edit Config に移動します。
- claude_desktop_config.json ファイルに OpenSearch MCP サーバーを追加します。

```json
{
  "mcpServers": {
    "opensearch-mcp-server": {
      "command": "uvx",
      "args": ["test-opensearch-mcp"],
      "env": {
        // 必須
        "OPENSEARCH_URL": "<your_opensearch_domain_url>",

        // 基本認証の場合
        "OPENSEARCH_USERNAME": "<your_opensearch_domain_username>",
        "OPENSEARCH_PASSWORD": "<your_opensearch_domain_password>",

        // IAM ロール認証の場合
        "AWS_REGION": "<your_aws_region>",
        "AWS_ACCESS_KEY": "<your_aws_access_key>",
        "AWS_SECRET_ACCESS_KEY": "<your_aws_secret_access_key>",
        "AWS_SESSION_TOKEN": "<your_aws_session_token>"
      }
    }
  }
}
```

ステップ 2: チャットを始める

Claude for Desktop で新しいチャットを開くと、利用可能な OpenSearch ツールがチャットウィンドウに表示されます。すぐに OpenSearch データについての質問を始めることができます。以下の画像にサンプルチャットが示されています。

![](https://storage.googleapis.com/zenn-user-upload/2b052f8d8235-20250516.png)

## セクション 2: OpenSearch MCP クライアント

包括的な MCP サポートの一環として、実験的機能として OpenSearch のエージェントに MCP クライアント機能も追加しています。OpenSearch 3.0 から、[会話型エージェント](https://docs.opensearch.org/docs/latest/ml-commons-plugin/agents-tools/agents/conversational/)と新しく導入された [Plan-Execute-Reflect エージェント](https://docs.opensearch.org/docs/latest/ml-commons-plugin/agents-tools/agents/plan-execute-reflect/)は、外部 MCP サーバーに接続してそのツールを使用できます。追加のエージェントタイプのサポートもまもなく利用可能になります!

### クイックスタート

[完全なドキュメント](https://docs.opensearch.org/docs/latest/ml-commons-plugin/agents-tools/mcp/mcp-connector/)は詳細なステップバイステップの手順を提供していますが、以下は簡略化されたプロセスの概要です。

ステップ 1: MCP コネクタを作成する — コネクタは MCP サーバーへの接続詳細を保存します。

ステップ 2: LLM を登録する — LLM はエージェントの推論能力を強化します。

ステップ 3: MCP ツールでエージェントを設定する — AI エージェントは LLM と OpenSearch の強力なデータ取得機能を統合します。

```json
"parameters": {
    "_llm_interface": "openai/v1/chat/completions",
    "mcp_connectors": [
        {
        "mcp_connector_id": "<YOUR_CONNECTOR_ID>",
        "tool_filters": [
            "^get_forecast",
            "get_alerts"
        ]
        }
    ]
}
```

tool_filters パラメータは特に強力です。エージェントがアクセスできる外部ツールを正確に制御できます。Java スタイルの正規表現を使用して公開するツールを選択できます。

- MCP サーバーからすべてのツールを許可する (空の配列)。
- 正確な名前でツールを選択する (search_indices)。
- 正規表現パターンでツールを選択する (^get_forecast は "get_forecast" で始まるすべてのツールを選択)。

ステップ 4: エージェントを実行する — Execute Agent API を呼び出して登録されたエージェントを呼び出します。

エージェントは tools 配列で指定された OpenSearch ツールと、ツールフィルターに基づいて MCP サーバーから選択されたツールの両方を使用します。

### エンドツーエンドの例: クロスクラスターデータアクセス

この例は、MCP がエージェントに複数の OpenSearch クラスター間でデータにアクセスする能力を与える方法を示しています。

**シナリオ**

- クラスター A には products インデックスに製品カタログデータが含まれています。
- クラスター B には product_ratings インデックスに製品評価データが含まれています。
- 目標: クラスター A のエージェントが両方のクラスターからのデータに基づいて質問に答えられるようにする。

**セットアップ**

- データセット: [模擬製品データ](https://github.com/rithin-pullela-aws/opensearch-mock-data)
- クラスター A ツール: ListIndexTool_ClusterA, IndexMappingTool_ClusterA, SearchIndexTool_ClusterA
- クラスター B ツール（MCP を通じてアクセス）: ListIndexTool_ClusterB, IndexMappingTool_ClusterB, SearchIndexTool_ClusterB

**エージェントの実行**

[計画-実行-振り返りエージェント](https://docs.opensearch.org/docs/latest/ml-commons-plugin/agents-tools/agents/plan-execute-reflect/)を使用して、次の質問をします。

```
You have access to data from 2 OpenSearch clusters, Cluster A and Cluster B. Using data from these clusters, answer this: List 10 kid toy products with high ratings.
```

エージェントは手順の詳細な内訳で応答します。

```
# 高評価の子供向けおもちゃ製品トップ 10

OpenSearch クラスター A と B のデータ分析に基づいて、以下の高評価の子供向けおもちゃ製品を特定しました。

1. **Fisher-Price Laugh & Learn Smart Stages Puppy (10/10)**
   - 75 以上の歌、音、フレーズを持つインタラクティブなぬいぐるみ
   - 赤ちゃんの成長に合わせて適応する 3 つの学習レベル
   - 対象年齢: 6-36 ヶ月

2. **Melissa & Doug Farm Animals Sound Puzzle (10/10)**
   - リアルな動物の音を持つ 8 ピースの木製パズル
   - マッチングとリスニングスキルを発達させる教育玩具
   - 対象年齢: 2 歳以上

3. **American Girl Bitty Baby Doll (9/10)**
   - 金髪と青い目を持つ 15 インチの赤ちゃん人形
   - Bitty Bear ぬいぐるみとスターターアウトフィットを含む
   - 対象年齢: 3 歳以上

4. **Ravensburger Jungle Animals 100-Piece Puzzle (9/10)**
   - リネン仕上げの高品質カードボードパズル
   - カラフルなジャングルテーマの 100 ピースパズル
   - 対象年齢: 6 歳以上

5. **Dora the Explorer Toddler Backpack (9/10)**
   - おもちゃや用品を運ぶためにデザインされたミニバックパック
   - ドーラとブーツの遊園地アドベンチャーテーマを特徴とする
   - 対象年齢: 3-5 歳

6. ...

## 分析手法

私は以下の手順でこの分析を行いました。

1. まず、両方のクラスターで製品関連のインデックスをすべて特定しました
   - クラスター A: 製品説明を含む 'products' インデックス
   - クラスター B: 製品評価を含む 'product_ratings' インデックス

2. マッピングツールを使用してインデックス構造を調べました
   - products インデックスには product_id とテキストフィールドが含まれています
   - product_ratings インデックスには product_id と rating フィールドが含まれています

3. 以下のようなキーワードを使用しておもちゃ製品を見つけるために複数の対象検索を実行しました
   - toy, game, puzzle, stuffed, doll, action figure, board game, LEGO
   - Fisher-Price, Melissa & Doug などのブランドの追加検索

4. おもちゃアイテムの製品 ID をクラスター B からの評価と相互参照しました

5. 結果をコンパイルし、評価順にソートして、最高評価の子供向けおもちゃ製品トップ 10 を特定しました

6. ...

最終リストには、教育玩具、ぬいぐるみ、パズル、人形、ビルディングセット、乗り物、アクショントイ、ボードゲームなど、複数のカテゴリにわたる多様なおもちゃが含まれています。完璧な 10/10 評価を持つ 2 つの製品（Fisher-Price Laugh & Learn Smart Stages Puppy と Melissa & Doug Farm Animals Sound Puzzle）はどちらも幼い子供向けに設計された教育玩具です。
```

## まとめ

MCP は AI 検索統合への変革的なアプローチを表し、AI エージェントが OpenSearch データや外部ツールとどのように対話するかを標準化します。

組み込み OpenSearch MCP サーバーは、AI エージェントが検索および分析データとどのように対話できるかにおいて重要な進歩を表しています。標準化されたインターフェースを提供することで、カスタム統合コードの必要性を排除し、エージェント型検索および分析アプリケーションのより迅速で安全なデプロイメントを可能にします。現在は実験的ですが、OpenSearch 3.0 の MCP サーバーは、貴重な検索データとのより洗練された AI エージェントの対話のための基盤を築きます。

スタンドアロン OpenSearch MCP サーバーは、高度な AI 機能と OpenSearch の以前のバージョンの間のギャップを埋めます。バージョン 3.0 にアップグレードすることなく、既存の OpenSearch デプロイメントで AI エージェントのパワーを活用できます。Claude、LangChain、または他のエージェントフレームワークを使用している場合でも、スタンドアロンサーバーは AI モデルを貴重な検索データに接続するための標準化された方法を提供します。

現在の実装はコア検索機能へのアクセスを提供し、将来的にはバージョン固有のツール互換性を強化する計画があります。公式リリースの準備をする中で、デモバージョンを探索し、フィードバックを共有することを歓迎します。皆様のご意見は、このソリューションをコミュニティのニーズにより適合させるのに役立ちます。

OpenSearch MCP クライアントは、OpenSearch エージェントが MCP プロトコルを通じて外部ツールプロバイダーに接続することを可能にし、ネイティブの OpenSearch 機能を超えてその能力を大幅に拡張します。組み込みツールに限定されるのではなく、エージェントは天気予報、翻訳 API、ドキュメント処理ツールなどの特殊な外部サービスを使用できます。この相互運用性は、OpenSearch エージェントを多様なシステムとデータソース間で調整できる多用途なオーケストレーターとして位置づけるのに役立ちます。この実験的機能が成熟するにつれて、OpenSearch エージェントが複雑な複数ステップのタスクを実行する能力を高める MCP 互換ツールの成長するエコシステムが予想されます。

## MCP を試す

AI エージェントがデータとどのように対話するかを変革するために、MCP を試して、ご意見をお聞かせください。OpenSearch 3.0 でこれらの機能を探索するだけでなく、この新興標準の開発に貢献することも歓迎します。[ML Commons リポジトリ](https://github.com/opensearch-project/ml-commons/)または [OpenSearch フォーラム](https://forum.opensearch.org/)でのフィードバックをお待ちしています!
