---
title: "[翻訳] コスト効率とパフォーマンスのための推論プロセッサの最適化"
emoji: "🔍"
type: "tech"
topics:
  - "opensearch"
published: true
published_at: "2025-06-02 22:33"
---

推論プロセッサ（`text_embedding`、`text_image_embedding`、`sparse_encoding` など）は、ドキュメントの取り込みや更新時にベクトル埋め込みを生成することを可能にします。現在、これらのプロセッサは、埋め込みのソースフィールドが変更されていなくても、ドキュメントが取り込まれたり更新されたりするたびに毎回モデル推論を呼び出します。これにより、不要な計算リソースの使用とコスト増加につながる可能性があります。

このブログ投稿では、冗長な推論呼び出しを削減し、コストを下げ、全体的なパフォーマンスを向上させる新しい推論プロセッサの最適化を紹介します。

## 最適化の仕組み

この最適化では、更新されたドキュメント内の埋め込みソースフィールドを既存のドキュメントと比較するキャッシュメカニズムを追加します。埋め込みフィールドに変更がない場合、プロセッサは新しい推論をトリガーする代わりに、既存の埋め込みを更新されたドキュメントに直接コピーします。フィールドが異なる場合、プロセッサは通常通り推論を実行します。以下の図はこのワークフローを示しています。

![最適化ワークフロー](https://storage.googleapis.com/zenn-user-upload/07c6dc6a78b7-20250602.png)

このアプローチにより、冗長な推論呼び出しを最小限に抑え、埋め込みの精度や鮮度に影響を与えることなく効率を大幅に向上させます。

## 最適化の有効化方法

この最適化を有効にするには、インジェストパイプラインプロセッサ定義で `skip_existing` パラメータを `true` に設定します。このオプションは [`text_embedding`](#text-embedding-processor)、[`text_image_embedding`](#textimage-embedding-processor)、および [`sparse_encoding`](#sparse-encoding-processor) プロセッサで利用できます。デフォルトでは、`skip_existing` は `false` に設定されています。

### テキスト埋め込みプロセッサ

[`text_embedding` プロセッサ](https://docs.opensearch.org/docs/latest/ingest-pipelines/processors/text-embedding/) は、セマンティック検索で一般的に使用されるテキストフィールドのベクトル埋め込みを生成します。

* **最適化の動作**: `skip_existing` が `true` の場合、プロセッサは `field_map` でマッピングされたテキストフィールドが変更されたかどうかをチェックします。変更がない場合、推論はスキップされ、既存のベクトルが再利用されます。

**パイプライン例**:

```json
PUT /_ingest/pipeline/optimized-ingest-pipeline
{
  "description": "最適化されたインジェストパイプライン",
  "processors": [
    {
      "text_embedding": {
        "model_id": "<model_id>",
        "field_map": {
          "text": "<vector_field>"
        },
        "skip_existing": true
      }
    }
  ]
}
```

### テキスト/画像埋め込みプロセッサ

[`text_image_embedding` プロセッサ](https://docs.opensearch.org/docs/latest/ingest-pipelines/processors/text-image-embedding/) は、マルチモーダル検索ユースケース向けにテキストと画像フィールドから組み合わせた埋め込みを生成します。

* **最適化の動作**: 埋め込みはテキストと画像フィールドの組み合わせから生成されるため、`field_map` でマッピングされたテキストと画像フィールドの**両方**が変更されていない場合にのみ推論はスキップされます。

**パイプライン例**:

```json
PUT /_ingest/pipeline/optimized-ingest-pipeline
{
  "description": "最適化されたインジェストパイプライン",
  "processors": [
    {
      "text_image_embedding": {
        "model_id": "<model_id>",
        "embedding": "<vector_field>",
        "field_map": {
          "text": "<input_text_field>",
          "image": "<input_image_field>"
        },
        "skip_existing": true
      }
    }
  ]
}
```

### スパース符号化プロセッサ

[`sparse_encoding` プロセッサ](https://docs.opensearch.org/docs/latest/ingest-pipelines/processors/sparse-encoding/) は、ニューラルスパース検索で使用されるテキストフィールドからスパースベクトルを生成します。

* **最適化の動作**: `field_map` 内のテキストフィールドに変更がない場合、プロセッサは推論をスキップし、既存のスパース符号化を再利用します。

**パイプライン例**:

```json
PUT /_ingest/pipeline/optimized-ingest-pipeline
{
  "description": "最適化されたインジェストパイプライン",
  "processors": [
    {
      "sparse_encoding": {
        "model_id": "<model_id>",
        "prune_type": "max_ratio",
        "prune_ratio": "0.1",
        "field_map": {
          "text": "<vector_field>"
        },
        "skip_existing": true
      }
    }
  ]
}
```

## パフォーマンス結果

冗長な推論をスキップすることで計算コストを削減するだけでなく、レイテンシーも大幅に低減します。以下のベンチマークは、`skip_existing` 最適化の有無によるプロセッサのパフォーマンスを比較しています。

### テスト環境

ベンチマークテストを実行するために以下のクラスターセットアップを使用しました。

![クラスターセットアップ](https://storage.googleapis.com/zenn-user-upload/25c2269a07d0-20250602.png)


### テキスト埋め込みプロセッサ

* **モデル**: `huggingface/sentence-transformers/msmarco-distilbert-base-tas-b`
* **データセット**: [Trec-Covid](https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/trec-covid.zip)

**サンプルリクエスト**

単一ドキュメント:

```json
PUT /test_index/_doc/1
{
  "text": "Hello World"
}
```

バルク更新:

```json
POST _bulk
{ "index": { "_index": "test_index" } }
{ "text": "hello world" }
{ "index": { "_index": "test_index" } }
{ "text": "Hi World" }
```

以下の表は `text_embedding` プロセッサのベンチマークテスト結果を示しています。

| 操作タイプ | ドキュメントサイズ | バッチサイズ | ベースライン (`skip_existing`=false) | 更新 (`skip_existing`=true) | ベースラインとの差 | 変更なし (`skip_existing`=true) | ベースラインとの差 |
| -------------- | -------- | ---------- | ------------------------------- | ---------------------------- | -------------- | ------------------------------- | -------------- |
| 単一更新  | 3,000    | 1          | 1,400,710 ms                    | 1,401,216 ms                  | +0.04%         | 292,020 ms                      | -79.15%        |
| バッチ更新   | 171,332  | 200        | 2,247,191 ms                    | 2,192,883 ms                  | -2.42%         | 352,767 ms                      | -84.30%        |

### テキスト/画像埋め込みプロセッサ

* **モデル**: `amazon.titan-embed-image-v1`
* **データセット**: [Flickr Image](https://www.kaggle.com/datasets/hsankesara/flickr-image-dataset)

**サンプルリクエスト**

単一ドキュメント:

```json
PUT /test_index/_doc/1
{
  "text": "Orange table",
  "image": "bGlkaHQtd29rfx43..."
}
```

バルク更新:

```json
POST _bulk
{ "index": { "_index": "test_index" } }
{ "text": "Orange table", "image": "bGlkaHQtd29rfx43..." }
{ "index": { "_index": "test_index" } }
{ "text": "Red chair", "image": "aFlkaHQtd29rfx43..." }
```

以下の表は `text_image_embedding` プロセッサのベンチマークテスト結果を示しています。

| 操作タイプ | ドキュメントサイズ | バッチサイズ | ベースライン     | 更新      | ベースラインとの差 | 変更なし    | ベースラインとの差 |
| -------------- | -------- | ---------- | ------------ | ------------ | ------------- | ------------ | -------------- |
| 単一更新  | 3,000    | 1          | 1,060,339 ms | 1,060,785 ms | +0.04%        | 465,771 ms   | -56.07%        |
| バッチ更新   | 31,783   | 200        | 1,809,299 ms | 1,662,389 ms | -8.12%        | 1,571,012 ms | -13.17%        |


### スパース符号化プロセッサ

* **モデル**: `huggingface/sentence-transformers/msmarco-distilbert-base-tas-b`
* **データセット**: [Trec-Covid](https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/trec-covid.zip)
* **プルーニング方法**: `max_ratio`, **比率**: `0.1`

**サンプルリクエスト**

単一ドキュメント:

```json
PUT /test_index/_doc/1
{
  "text": "Hello World"
}
```

バルク更新:

```json
POST _bulk
{ "index": { "_index": "test_index" } }
{ "text": "hello world" }
{ "index": { "_index": "test_index" } }
{ "text": "Hi World" }
```

以下の表は `sparse_encoding` プロセッサのベンチマークテスト結果を示しています。

| 操作タイプ | ドキュメントサイズ | バッチサイズ | ベースライン     | 更新      | ベースラインとの差 | 変更なし  | ベースラインとの差 |
| -------------- | -------- | ---------- | ------------ | ------------ | ------------- | ---------- | -------------- |
| 単一更新  | 3,000    | 1          | 1,942,907 ms | 1,965,918 ms | +1.18%        | 306,766 ms | -84.21%        |
| バッチ更新   | 171,332  | 200        | 3,077,040 ms | 3,101,697 ms | +0.80%        | 475,197 ms | -84.56%        |

## 結論

コストとパフォーマンスの結果が示すように、`skip_existing` 最適化は冗長な推論操作を大幅に削減し、これによりコスト削減とシステムパフォーマンスの向上につながります。入力フィールドが変更されていない場合に既存の埋め込みを再利用することで、インジェストパイプラインは更新をより速く、より効率的に処理できます。この戦略はシステムパフォーマンスを向上させ、スケーラビリティを強化し、大規模でより費用対効果の高い埋め込み検索を実現します。

## 次のステップ

Bulk API をインジェストパイプラインと共に使用する場合、異なる操作がどのように動作するかを理解することが重要です。

Bulk API は `index` と `update` の 2 つの操作をサポートしています:

* `index` 操作はドキュメント全体を置き換え、インジェストパイプラインを**トリガー**します。
* `update` 操作は指定されたフィールドのみを変更しますが、現在はインジェストパイプラインを**トリガーしません**。

Bulk API リクエストの `update` 操作にインジェストパイプラインのサポートを追加してほしい場合は、[この GitHub issue](https://github.com/opensearch-project/OpenSearch/issues/17494) に +1 を追加してサポートを検討してください。
