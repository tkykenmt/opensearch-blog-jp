---
title: "[翻訳] アルゴリズム改善による誤検知の削減"
emoji: "🎯"
type: "tech"
topics: ["opensearch", "anomalydetection", "machinelearning", "observability", "algorithm"]
published: false
published_at: 2025-02-05
publication_name: "opensearch"
---

:::message
本記事は [OpenSearch Project Blog](https://opensearch.org/blog/) に投稿された以下の記事を日本語に翻訳したものです。
:::

https://opensearch.org/blog/reducing-false-positives-through-algorithmic-improvements/

OpenSearch の異常検出プラグインは、[Random Cut Forest (RCF)](https://github.com/aws/random-cut-forest-by-aws/) アルゴリズムによって動作しています。RCF は強力なアルゴリズムですが、誤報はユーザーがアラームの検証と却下に時間を費やす必要があるため、その実用的な価値を低下させます。この問題に対処するため、OpenSearch 2.17 では、異常検出チームが RCF に 4 つの主要な機能強化を導入し、誤検知を大幅に削減しました。本記事では、OpenSearch の RCF アルゴリズムに対する 4 つの主要なアルゴリズム改善について説明します。これらの改善により、高い検出精度を維持しながら誤検知が 94.3% 削減されました。また、実際のケーススタディを通じてこれらの改善を実証し、以前の OpenSearch バージョンとの詳細な比較を提供します。

## RCF の制限

以下のセクションでは、RCF アルゴリズムの制限について説明します。

### 繰り返し発生する周期的なスパイク

強い日次または週次パターンを持つデータで異常を検出することは困難な場合があります。RCF は定期的に発生するスパイクをフィルタリングするのに苦労し、これらの正常で繰り返し発生するイベントを異常としてフラグ付けします。

![周期的なスパイク](/images/opensearch-reducing-false-positives-algo/periodic-1024x522.png)

季節的な動作を捉える自然なアプローチは、モデルが完全なサイクルを観察できるようにシングルサイズを増やすことです。このデータセットでは 1 日に相当します。データは 5 分ごとに収集されたため、1 日は 288 データポイントに相当します。前の図では、デフォルトのシングルサイズ 8 (異常検出プラグイン内) が使用されました。次の図では、1 日分のデータを捉えるためにシングルサイズを 288 に増やしました。この大きなシングルサイズはモデルが日次パターンを学習するのに役立ちますが、偽陰性も導入する可能性があります。RCF は、1 つは異常に大きく、1 つは異常に小さい、2 つの真に異常なスパイクを見落とすようになりました。

![シングルサイズを増やした周期的なスパイク](/images/opensearch-reducing-false-positives-algo/periodic_shingle-1024x520.png)

### データドリフトとレベルシフト中の移行期間

データは、分布の緩やかな変化 (データドリフト) またはベースラインの突然のシフト (レベルシフト) を示すことがあります。RCF はストリーミングと継続的学習を通じてこれらの変化に適応するように設計されていますが、調整には時間が必要です。次の図では、レベルシフトが発生した後、RCF は安定して新しいベースラインを受け入れる前に 4 つの誤検知を生成しています。

![レベルシフト](/images/opensearch-reducing-false-positives-algo/level_shift-1024x429.png)

### 正常な変動と真の異常の比較

データは、真の異常と間違えるべきではない通常の変動を示すことがよくあります。最初は、RCF は過度に敏感で、これらの正常な変動を異常としてフラグ付けする可能性があります。ただし、変化が平均周辺の典型的な分散範囲内にとどまる場合、それらは真の異常ではなく正常な動作を表します。次の図では、3 月 17〜18 日頃のディスク書き込みスパイクは大きく見えますが、予想範囲内にあるため、実際の異常ではありません。

![分散](/images/opensearch-reducing-false-positives-algo/variance.png)

## RCF の制限の克服

OpenSearch 2.17 では、前のセクションで説明した制限に対処するために、RCF アルゴリズムに以下の改善が導入されました。

### 候補異常の統計的追跡

繰り返し発生する周期的なスパイクに対処するために、モデルは異常に見えるポイント (高い RCF スコアを持つポイント) に対して特別に統計的追跡を採用しています。すべてのデータポイントのグローバル統計を更新するのではなく、RCF はこの小さな候補異常セットに対して (指数減衰を伴う) 実行平均と分散を維持します。高スコアイベントが発生すると、モデルは 2 つの値セットを比較することで、それが以前の高スコア観測に似ているかどうかを確認します。

* **実際の観測値とその実行平均**: RCF は、観測されたデータが許容限度内でその実行平均の近くにとどまっているかどうかを検証します。
* **期待される観測値とその実行平均**: モデルは、期待される (補完された) 値も調べ、それらが独自の実行平均の周りにクラスタリングし続けることを確認します。このステップは、ベースラインが適切に進化していることを確認するのに役立ちます。

実際の値と期待される値の両方が更新された許容範囲内にとどまる場合、アルゴリズムはそれらを異常としてフラグ付けするのを停止します。

### グループ化されたアラート

データドリフトまたはレベルシフト中の移行期間を処理するために、アルゴリズムはグループ化されたアラートをサポートしています。複数の異常なイベントがほぼ同時に (1 つの時間ウィンドウ、または *シングル* 内で) 発生した場合、多くのアラートではなく 1 つのアラートのみを受け取ります。このアプローチは、システムがまだ新しい条件に適応している間に、冗長なアラートでユーザーを圧倒することを防ぎます。

### 異常検出のための近似最近傍の使用

候補イベントが真の異常なのか単なる正常な変動なのかを判断する際、RCF は以下のアプローチを使用して近似最近傍を考慮します。

1. **期待値ベクトルの構築**: RCF は、疑わしい特徴を典型的な履歴値に置き換えることで、クエリされたポイントの「正常な」バージョンを作成します。
2. **各ツリーで近傍を見つける**: RCF は、期待されるベクトルに近いリーフノードを見つけるために、分割次元に沿って各ツリーを走査します。近さは、近傍が期待されるベクトルからどれだけ離れることができるかを決定するスケーリング係数 CC (例: CC = 1.1) を使用して測定されます。十分な数のツリー (例: 少なくとも 10%) が CC に平均距離を掛けた範囲内で近傍を検出した場合、イベントは正常である可能性が高いと見なされます。
3. **「セーフボックス」の決定**: RCF は、最近のノイズレベルや平均偏差などの要因に基づいて、元のポイントの周りに「セーフボックス」も定義します。ほとんどの近傍がこのボックス内にある場合、ポイントは「説明可能」と見なされます。ボックス内に入る近傍が少なすぎる場合、ポイントは異常としてフラグ付けされます。

### 期待値ベクトルを使用した再スコアリング

軽微な変動や移行期間 (データドリフトやレベルシフトなど) による誤検知をさらに削減するために、RCF は期待値ベクトルを使用して異常スコアを再スケーリングします。基本的に、新しいスコアを計算するために、潜在的に異常なセグメントを類似の履歴値に置き換えます。この「期待される」スコアと元のスコアの差がスケーリングされたしきい値 (以前の異常のスコアと現在のしきい値を考慮) を下回る場合、RCF は別のアラートを発生させません。この戦略は、同じ異常に対する繰り返しの通知を回避するのに役立ちます。

## Numenta Anomaly Benchmark を使用した RCF の評価

これらの改善をテストするために、異常検出チームは [Numenta Anomaly Benchmark (NAB)](https://github.com/numenta/NAB) からのラベル付き Amazon CloudWatch メトリクスを使用して RCF を評価しました。データセットには、CPU 使用率、受信ネットワークトラフィック (バイト単位)、ディスク書き込みアクティビティ (バイト単位) などの AWS サーバーパフォーマンスメトリクスが含まれています。これらのデータセットには、異常パターンを識別するための信頼できる参照として機能する Numenta によって提供された検証済みの異常ラベルも含まれています。

### テスト構成

テストには以下の RCF 構成を使用しました。

* 50 本のツリー、各ツリーは 256 サンプルでトレーニング
* シングルサイズ 8
* 40 データポイントのウォームアップ期間
* 実際の値が期待値から少なくとも 20% 逸脱する必要があるという制約

これらの設定は、異常検出プラグインのデフォルト RCF パラメータと一致しています。

さらに、RCF は各データポイントに 0 から 1 の範囲の異常グレードを割り当てます。グレード 0 は正常なイベントを示し、0 より大きい値は潜在的な異常を表します。グレードが 1 に近いほど、異常の可能性が高くなります。このケーススタディでは、低い可能性の異常をフィルタリングするために 0.5 のしきい値を使用しました。

### 結果

以下のセクションでは、さまざまなメトリクスのテスト結果を提供します。

#### CPU 使用率

* **データセット**: NAB AWS `ec2_cpu_utilization_24ae8d`
* **総レコード数**: 4,031
* **ラベル付き異常**:
  + 2014-02-26 22:05:00 (検出済み)
  + 2014-02-27 17:15:00 (検出済み)
* **RCF 異常総数**: 3

![CPU 使用率](/images/opensearch-reducing-false-positives-algo/cpu.png)

#### 受信ネットワークトラフィック

* **データセット**: NAB AWS `ec2_network_in_257a54`
* **総レコード数**: 4,031
* **ラベル付き異常**:
  + 2014-04-15 16:44:00 (検出済み)
* **RCF 異常総数**: 4

![ネットワークトラフィック](/images/opensearch-reducing-false-positives-algo/network-1024x461.png)

#### ディスク書き込みアクティビティ

* **データセット**: NAB AWS `ec2_disk_write_bytes_1ef3de`
* **総レコード数**: 4,718
* **ラベル付き異常**:
  + 2014-03-10 21:09:00 (検出済み)
* **RCF 異常総数**: 3

![ディスク書き込み](/images/opensearch-reducing-false-positives-algo/disk-1024x467.png)

#### RDS CPU 使用率 (rds_cpu_utilization_e47b3b)

* **データセット**: NAB AWS `rds_cpu_utilization_e47b3b`
* **総レコード数**: 4,031
* **ラベル付き異常**:
  + 2014-04-13 06:52:00 (検出済み)
  + 2014-04-18 23:27:00 (検出済み)
* **RCF 異常総数**: 2

![RDS CPU 使用率](/images/opensearch-reducing-false-positives-algo/rds.png)

#### RDS CPU 使用率 (rds_cpu_utilization_cc0c53)

* **データセット**: NAB AWS `rds_cpu_utilization_cc0c53`
* **総レコード数**: 4,031
* **ラベル付き異常**:
  + 2014-02-25 07:15:00 (検出済み)
  + 2014-02-27 00:50:00 (未検出)
* **RCF 異常総数**: 1

![RDS CPU 使用率 cc0c53](/images/opensearch-reducing-false-positives-algo/rds_cc-1024x470.png)

## 適合率と再現率

結果を提示する前に、機械学習評価における 2 つの重要な概念を定義しましょう。

* **適合率**: 検出された異常のうち正しいものの割合。アルゴリズムが検出したすべての異常のうち、実際に異常だったものはいくつか？高い適合率は誤った識別が少ないことを意味します。例えば、アルゴリズムが 10 個の異常を検出し、8 個が実際に異常である場合、適合率は 8/10=0.8、つまり 80% です。
* **再現率**: 検出された真の異常の割合。すべての真の異常のうち、アルゴリズムが検出したものはいくつか？高い再現率は見逃した異常が少ないことを意味します。例えば、10 個の真の異常があり、アルゴリズムがそのうち 8 個を検出した場合、再現率は 8/10=0.8、つまり 80% です。

### 結果

以下の表は、NAB CloudWatch ベンチマークを使用した RCF の適合率と再現率のパフォーマンスをまとめています。

| データセット | 適合率 | 再現率 |
| --- | --- | --- |
| AWS `ec2_cpu_utilization_24ae8d` | 0.67 | 1 |
| AWS `ec2_network_in_257a54` | 0.25 | 1 |
| AWS `ec2_disk_write_bytes_1ef3de` | 0.33 | 1 |
| AWS `rds_cpu_utilization_e47b3b` | 1 | 1 |
| AWS `rds_cpu_utilization_cc0c53` | 1 | 0.5 |

全体として、RCF は強い再現率を示し、データセット全体で 8 個中 7 個の異常を正しく検出しました。特に、5 つのデータセットのうち 4 つで完全な再現率を達成しました。

RCF は高い適合率も維持しています。ほとんどの誤検知は、モデルが正確な予測を行うのに十分な履歴データを蓄積する前の時系列の早い段階で発生します。例えば、次のグラフでは、`ec2_network_in_257a54` データセットの 4 月 12 日 3:14 頃に検出された異常は特に注目に値します。これは、以前に観察された均一なダブルスパイクのパターンから逸脱しています。以前のパターンでは、2 番目のスパイクが約 5 分以内に減少していますが、この異常なスパイクは約 10 分続く延長された減少を示しています。

![ネットワークズームイン 1](/images/opensearch-reducing-false-positives-algo/network_zoom_in_1-1024x542.png)

データセットの最初の 20% を試用期間として除外すると、データセット全体で適合率が向上します。この調整は、十分な履歴データを観察した後、RCF がより正確になることを強調しています。データセットの最後の 80% の結果を以下の表にまとめます。

| データセット | 適合率 | 再現率 |
| --- | --- | --- |
| AWS ec2_cpu_utilization_24ae8d | 1 | 1 |
| AWS ec2_network_in_257a54 | 0.5 | 1 |
| AWS ec2_disk_write_bytes_1ef3de | 1 | 1 |
| AWS rds_cpu_utilization_e47b3b | 1 | 1 |
| AWS rds_cpu_utilization_cc0c53 | 1 | 0.5 |

別のタイプの誤検知は、検出された異常がデータに基づいて有効に見えるが、実際には異常としてラベル付けされていない場合に発生します。例えば、次のグラフでは、`ec2_network_in_257a54` データセットの 4 月 15 日約 3:34 に検出された異常は、ペアスパイクの典型的なパターンから逸脱しています。通常の 2 つの連続したピークの代わりに、このイベントは単一のスパイクを示しています。これは確立されたパターンからの逸脱を表していますが、異常としてラベル付けされていません。

![ネットワークズームイン 3](/images/opensearch-reducing-false-positives-algo/network_zoom_in_3-1024x470.png)

## OpenSearch 2.17 と 2.9 の比較

OpenSearch 2.17 が OpenSearch 2.9 と比較して異常検出パフォーマンスをどのように改善したかを調べてみましょう。結果を提示する前に、以下の重要な概念を定義しましょう。

* **真陽性 (正しい検出)**: アルゴリズムによって異常として正しくフラグ付けされた真の異常イベント。
* **偽陽性 (誤報)**: アルゴリズムによって異常として誤ってフラグ付けされた非異常イベント。
* **偽陰性 (見逃した異常)**: システムが異常としてフラグ付けできなかった異常イベント。

### 結果

以下の表は、OpenSearch バージョン 2.9 と 2.17 の異常検出を比較しています。

| データセット | 2.9 検出異常数 | 2.9 真陽性 | 2.17 検出異常数 | 2.17 真陽性 | 実際の異常数 |
| --- | --- | --- | --- | --- | --- |
| AWS ec2_cpu_utilization_24ae8d | 17 | 1 | 3 | 2 | 2 |
| AWS ec2_network_in_257a54 | 33 | 1 | 4 | 1 | 1 |
| AWS ec2_disk_write_bytes_1ef3de | 16 | 1 | 3 | 1 | 1 |
| AWS rds_cpu_utilization_e47b3b | 23 | 2 | 2 | 2 | 2 |
| AWS rds_cpu_utilization_cc0c53 | 23 | 1 | 1 | 1 | 2 |
| **合計** | 112 | 6 | 13 | 7 | 8 |

### 考察

バージョン 2.17 は、バージョン 2.9 と比較して、誤報の全体的な削減と真のアラートの増加を示しました。

OpenSearch 2.9 は 112 個の異常をフラグ付けしましたが、真の異常は 6 個のみで、高い偽陽性率となりました。OpenSearch 2.17 でのアルゴリズム改善後、フラグ付けされた異常は 13 個のみで、そのうち 7 個が真の異常でした。これは、適合率が 5.4% (6/112) から 53.8% (7/13) に大幅に増加し、再現率が 75% (6/8) から 87.5% (7/8) に増加したことを反映しています。

比較すると、OpenSearch 2.9 は 106 個の偽陽性を生成しましたが、OpenSearch 2.17 はわずか 6 個でした。これは **偽陽性の 94.3% 削減** を表しています。この削減率は以下の式を使用して計算できます。

$$  
\text{偽陽性の削減率}  
= \frac{\text{旧 FP} – \text{新 FP}}{\text{旧 FP}} \times 100\%  
= \frac{106 – 6}{106} \times 100\% = 94.3\%  
$$

同様に、OpenSearch 2.9 は 2 個の実際の異常を見逃しましたが、OpenSearch 2.17 はわずか 1 個でした。これは **偽陰性の 50% 削減** を表し、以下のように計算されます。

$$  
\text{偽陰性の削減率}  
= \frac{\text{旧 FN} – \text{新 FN}}{\text{旧 FN}} \times 100\%  
= \frac{2 – 1}{2} \times 100\% = 50\%  
$$

全体として、OpenSearch 2.17 はバージョン 2.9 と比較して、偽陽性と偽陰性の両方を大幅に削減しました。

## 結論

OpenSearch 2.17 での RCF アルゴリズムの機能強化により、誤検知を削減することで異常検出が大幅に改善されました。主な改善点には、候補異常の履歴追跡、グループ化されたアラートの実装、最近傍による冗長なシグナルの抑制、期待値比較によるスコアの精緻化が含まれます。これらの更新は、高い再現率を維持しながら、周期的なスパイクなどの実際の課題に対処するのに役立ちます。NAB CloudWatch ベンチマークを使用した実証テストは、**偽陽性の 94.3% 削減** と **偽陰性の 50% 削減** でその有効性を実証しています。
