---
title: "[翻訳] Lucene HNSW のパフォーマンス: OS ページキャッシュの詳細分析"
emoji: "🔍"
type: "tech"
topics: ["opensearch", "lucene", "vectorsearch", "hnsw", "performance"]
publication_name: "opensearch"
published: true
published_at: 2026-02-09
---

:::message
本記事は [OpenSearch Project Blog](https://opensearch.org/blog/) に投稿された以下の記事を日本語に翻訳したものです。
:::

https://opensearch.org/blog/lucene-hnsw-performance-a-deep-dive-into-the-os-page-cache/

[OpenSearch k-NN プラグイン](https://opensearch.org/docs/latest/search-plugins/knn/index/)を使って強力なベクトル検索アプリケーションを構築し、パフォーマンスは素晴らしい状態です。クエリは高速で、結果も的確です。しかし、データが増えるにつれて状況が変わります。クエリの応答時間が遅くなり、不安定になる一方で、CPU は最大負荷に達していません。ダッシュボードを見つめながら、何が起きているのか頭を悩ませることになります。

この挙動は JVM ヒープではなく、このワークロードにおいて最も重要でありながら見落とされがちなリソース、つまりサーバーの利用可能なシステム RAM に起因しています。

本記事を読み終える頃には、このシステム RAM、Lucene セグメント、k-NN クエリパフォーマンスの深い関係を理解できるようになります。なぜ馴染みのある JVM ヒープが主役ではないのか、ボトルネックの診断方法、そしてクラスターを最適な持続的速度に設定する方法を学びます。

## 黄金律: ベクトル検索がすべてのファイルをチェックする理由

メモリがなぜこれほど重要なのかを理解するには、まずベクトル検索と従来のキーワード検索の根本的な違いを理解する必要があります。

キーワード検索を実行すると、OpenSearch は転置インデックスと呼ばれる非常に効率的なデータ構造を使用します。検索語を検索し、その語を含むドキュメントのリストを即座に取得できるため、データの大部分を無視できます。

ベクトル検索は異なる仕組みで動作します。高次元空間における近接性を測定しますが、最も近いベクトルがどこにあるかを示す単純なインデックスはありません。クエリに対する真の最近傍を確実に見つけるために、OpenSearch k-NN プラグインはシャード内の**すべての Lucene セグメント**のベクトルグラフに対して検索を実行する必要があります。これは、各セグメントが独自の単一の HNSW グラフファイルを持ち、永続的な 1 対 1 の関係を形成しているためです。1 つでもスキップすると、最良の結果を見逃す可能性があります。

このルール、つまりすべてのセグメントをチェックしなければならないということが、以降のすべての基盤となります。

このメモリの分割がパフォーマンスの鍵です。物理 RAM がどのように共有されるかを簡単に説明します。

- **JVM ヒープ用の一部**: OpenSearch プロセスが自身の操作に使用します。
- **残りは OS ページキャッシュ用**: オペレーティングシステムが HNSW グラフファイルを高速アクセスのためにロードする領域です。

これは、JVM ヒープだけでなく、利用可能なシステム RAM の合計が Lucene HNSW のパフォーマンスにとって重要なリソースである理由を示しています。

## 見えないヒーロー: OS ページキャッシュの仕組み

デフォルトの Lucene HNSW エンジンを使用する場合、k-NN プラグインは Faiss などの他のエンジンよりも効率的なメモリモデルに依存しています。グラフファイル全体のロードを必要とする**手動管理のオフヒープキャッシュ**を維持する代わりに、Lucene エンジンはオペレーティングシステムと直接統合します。ベクトルグラフの格納に JVM ヒープを使用せず、代わりに**メモリマップドファイル**を使用し、これは**オペレーティングシステムのページキャッシュ**によって提供されます。

仕組みは以下のとおりです。

1. **仮想ショートカットの作成**: シャードが開かれると、Lucene はオペレーティングシステムにディスク上の HNSW グラフファイルを OpenSearch プロセスの**仮想メモリ空間**にマッピングするよう指示します。これにより、実際に RAM にロードすることなく、ディスク上のファイルへの高速な「ショートカット」が作成されます。
2. **オンデマンドでのデータロード**: クエリがグラフを走査する際、これらの仮想メモリアドレスにアクセスします。ページが初めて必要になると、オペレーティングシステムがアクセスをインターセプトし、ファイルの該当部分をディスクから**ページキャッシュ**に読み込み、プロセスに返します。
3. **以降のアクセスは RAM から**: 同じページへの以降のリクエストは、ディスクを完全にバイパスして、メモリ速度でページキャッシュから直接提供されます。

このモデルはメモリ管理をオペレーティングシステムに委譲しており、OS はこのタスクに高度に最適化されています。ただし、パフォーマンスはページキャッシュのサイズに完全に依存します。

## パフォーマンスの 2 つの世界: RAM の物語

k-NN ワークロードは、サーバーの利用可能な RAM に基づいて、2 つの明確に異なるパフォーマンスシナリオのいずれかに該当します。両者の違いは根本的なものです。一方はメモリの速度で動作し、もう一方はディスク I/O の物理的なレイテンシーに制約されます。

### ワールド 1: 高速レーン (CPU バウンドパフォーマンス)

このシナリオでは、OS ページキャッシュに利用可能な RAM がアクティブな HNSW グラフを保持するのに十分です。初期ウォームアップ後、必要なデータページは物理 RAM に常駐します。クエリが実行されると、CPU はこのデータに直接アクセスでき、パフォーマンスは CPU の計算速度のみに制約されます。

**結果**: 高速で安定した **CPU バウンド**パフォーマンス。これが目標状態です。

### ワールド 2: 渋滞 (I/O バウンドパフォーマンス)

これは、HNSW グラフファイルが利用可能なページキャッシュよりも大きい場合に発生します。新しいメモリアクセスを処理するために、OS は最も最近使用されていない (LRU) ページをキャッシュから退避させて空きを作る必要があります。クエリがセグメントを反復処理する際、キャッシュにないページを常に要求し、OS にディスクからの読み取りを強制します。システムがストレージデバイスの速度にボトルネックされるこの非効率なサイクルは、**キャッシュスラッシング**と呼ばれます。

**結果**: 遅く不安定な **I/O バウンド**パフォーマンス。CPU はほとんどの時間をディスクの待機に費やします。

## 最適なパフォーマンスのための実践的ガイダンス

「高速レーン」状態を達成するには、設定に対する意図的なアプローチが必要です。I/O バウンドパフォーマンスが発生している場合 (`iostat` などのツールでディスクアクティビティを監視して診断できます)、ボトルネックを解消するために以下の考慮事項が重要です。

### メモリ要件の計算

インデックスを構築する前のキャパシティプランニングでは、ページキャッシュに必要な RAM を見積もることができます。数十億規模のベンチマークで使用される計算式は、信頼性の高い出発点です。

```
ページキャッシュ用 RAM ≈ 1.1 * (4 * d + 8 * m) * num_vectors
```

パラメータの内訳は以下のとおりです。

- **`d`**: ベクトルの次元数 (例: 1024)。
- **`m`**: HNSW グラフの各ノードが持つ接続数。これは設定可能なインデックスパラメータで、デフォルトは 16 です。値を大きくすると精度は向上しますが、メモリフットプリントが増加します。
- **`num_vectors`**: シャードに格納する予定のベクトルの総数。
- **`1.1`**: ファイルシステムおよびシステムレベルのキャッシュのオーバーヘッド約 10% を考慮した乗数。

この計算式は、データと目標精度に基づいてハードウェア要件を予測する強力な方法を提供し、「高速レーン」パフォーマンスを達成するのに十分な RAM をプロビジョニングできるようにします。

### JVM よりもページキャッシュを優先する

専用のベクトル検索ノードでは、JVM と OS の間で RAM を 50/50 に分割する標準的な方法は最適ではありません。より良い戦略は、OpenSearch の操作に十分な小さめのヒープ (例: 8〜32 GB) を割り当て、**サーバーの RAM の大部分を OS ページキャッシュに割り当てる**ことです。このアプローチは大規模テストで検証されており、数百ギガバイトの RAM を持つノードで 32 GB のヒープで正常に動作し、OS 用のメモリを最大化しています。これにより、OS がグラフをメモリに保持するために必要なリソースを確保できます。

### Force Merge によるインデックス構造の最適化

読み取り負荷の高いインデックスでは、[Force Merge API](https://opensearch.org/docs/latest/api-reference/index-apis/forcemerge/) を使用してシャードを単一のセグメントに統合することで、キャッシュ効率を大幅に向上させることができます。単一の連続したグラフファイルは、数十の小さな断片化されたファイルよりも OS がページキャッシュで管理しやすく予測可能であり、システムがスラッシングの影響を受けにくくなります。

## まとめ

Lucene HNSW エンジンのパフォーマンスは JVM チューニングの話ではなく、OS ページキャッシュに十分な RAM を供給する話です。メモリマップドファイルの仕組みを理解し、メモリ要件を計算し、OS を優先するようにノードを設定することで、予測不能な I/O バウンドパフォーマンスから、最新のベクトル検索が約束する安定した CPU バウンドの速度へと移行できます。これで、真に高性能な検索エンジンを構築・維持するためのメンタルモデルを手に入れました。
